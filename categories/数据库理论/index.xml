<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据库理论 on dboop.com</title>
    <link>/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA/</link>
    <description>Recent content in 数据库理论 on dboop.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 11 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关系型数据库是怎么工作的7:数据管理</title>
      <link>/post/2018/01/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%847%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%847%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</guid>
      <description>目录：
[TOC]
正文：
数据管理器 查询管理器解析优化好SQL后，开始进行执行SQL，需要表和索引中的数据。 它要求数据管理器获取数据，但是有两个问题：
 关系数据库使用事务模型。 因此，你做不到随时获取任意数据，因为其他人可能会同时使用/修改数据。 数据检索是数据库中最慢的操作，因此数据管理器必须足够聪明才能获取并将数据保留在内存缓冲区中。 在这一部分中，我们将看到关系数据库如何处理这两个问题。 我不会谈论数据管理器获取数据的方式，因为它不是最重要的。 我们分两部分介绍：缓存管理，事务管理  缓存管理Cache manager 我们知道，数据库的主要瓶颈是磁盘I/O。 为了提高性能，现代数据库使用缓存管理器。
查询执行程序不是直接从文件系统获取数据，而是向缓存管理器请求数据。 高速缓存管理器具有一个称为缓冲池的内存中高速缓存。 从内存中获取数据极大地加快了数据库的速度。
很难给出一个数量级，因为它取决于您需要执行的操作： - 顺序访问（例如：全表扫描）与随机访问（例如：按行ID进行访问）， - 读与写 以及数据库使用的磁盘类型： - 7.2k/10k/15k rpm HDD - SSD - RAID 1/5/…
但我想说内存比磁盘快100到10万倍。
但是，这导致了另一个问题（与数据库一样……）。 缓存管理器需要在查询执行程序使用它们之前获取内存中的数据； 否则查询管理器必须等待慢速磁盘中的数据。
 预读 此问题称为预先读取。 查询执行程序知道所需的数据，因为它知道查询的全部流程，并且知道磁盘上的数据以及统计信息。 按这样的逻辑： - 当查询执行程序正在处理其第一堆数据时 - 它要求缓存管理器(我们简称为CM)预加载第二组数据 - 开始处理第二组数据时 - 它要求CM预加载第三束，并通知CM可以从缓存中清除第一束。 - … CM将所有这些数据存储在其缓冲池中。 为了知道是否仍然需要数据，缓存管理器添加了有关缓存数据的额外信息（称为latch）。
有时，查询执行程序不知道需要什么数据，或者某些数据库不提供此功能。取而代之的是，他们使用推测性预取（例如：如果查询执行器要求提供数据1,3,5，在不久的将来很可能会要求提供7,9,11）或顺序预读（在这种情况下，CM只是从磁盘加载要求的数据后的下一个连续数据）。
为了监视预读的工作状况，现代数据库提供了一个称为缓冲区/高速缓存命中率的指标。命中率显示在不需要DISK访问就直接在缓存里找到数据的频率。
请注意：不良的缓存命中率并不总是意味着缓存无法正常工作。有关更多信息，您可以阅读Oracle文档。 https://docs.oracle.com/database/121/TGDBA/tune_buffer_cache.htm 但是，缓冲区是有限的内存。因此，它需要删除一些数据才能加载新数据。加载和清除缓存在磁盘和网络I/O方面要付出一定的代价。如果您有一个经常执行的查询，不断的加载然后清除该查询使用的数据会很笨拙。为了解决此问题，现代数据库使用缓冲区替换策略。
缓冲区替换策略 Buffer-Replacement strategies 现代数据库 (至少SQL Server, MySQL, Oracle and DB2)用 LRU算法.</description>
    </item>
    
    <item>
      <title>关系型数据库是怎么工作的6:SQL查询</title>
      <link>/post/2018/01/08/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%846sql%E6%9F%A5%E8%AF%A2/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/08/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%846sql%E6%9F%A5%E8%AF%A2/</guid>
      <description>查询管理器 上图标红的部分就是数据库的能力所在.在这里一个写得不好的(最初的)查询语句会被转换为一个高效的可执行代码.然后执行它,并将执行结果返回给客户端管理器. 这个操作可以分解成: - 首先检查SQL是否有效 - 然后重写这个SQL,去掉一些没用的操作,加上一些预先优化 - 然后优化SQL,提高性能并转化为可执行的数据访问计划 - 然后编译执行计划 - 最后,执行它
在接下来的部分,我们要讨论的不包含最后两部分(编译和执行),因为他们不重要
想更好的理解本篇文章的内容,建议你后续阅读以下内容:
 有关基于成本的优化的初步研究论文（1979年）：关系数据库管理系统中的访问路径选择。本文只有12页，中等难度。 DB2 9.X如何优化查询 非常好而深入的介绍 PostgreSQL如何优化查询的很好的演示 这是最易于访问的文档，因为它比“让我们看看PostgreSQL使用的算法”更多地是关于“让我们看看PostgreSQL在这些情况下给出的查询计划”。 有关优化的官方SQLite文档:https://www.sqlite.org/optoverview.html。易于阅读，因为SQLite使用简单的规则。而且，这是唯一真正说明其工作原理的官方文档。 关于Oracle 12c中的优化的白皮书 两本关于查询优化的理论课程，来自“数据库系统概念”一书的作者。重点放在磁盘I/O成本方面的读物不错，但在CS方面也需要良好的水平。课程1 课程2 我发现另一门理论课程可以访问，但只侧重于联接运算符和磁盘I/O。 课程3  1.查询解析器 每个SQL语句都会发送到解析器，在该处检查语法是否正确。如果查询中有错误，解析器将拒绝该查询。例如，如果您写的是“SLECT…”而不是“SELECT…”，则故事到此结束。
更进一步。它还检查关键字是否以正确的顺序使用。例如，SELECT之前的WHERE将被拒绝。
然后，分析查询中的表和字段。解析器使用数据库的元数据来检查：
 表是否存在 表中的字段是否存在 是否可以对字段类型进行操作（例如，不能对整数使用substring函数） 然后，它检查您是否具有读取（或写入）SQL中的表的权限。同样，这些对表的访问权限由您的DBA设置。  在此解析期间，SQL查询将转换为内部表示形式（通常为树）
如果一切正常，则将内部表示形式发送到查询重写器。
2.查询重写器 在此步骤中，我们已经有了上一步结果的SQL内部表示。重写器的目的是：
 预优化查询 避免不必要的操作 帮助优化器找到最佳解决方案   重写器在sql查询中执行已知规则的清单。如果查询符合规则模式，则将应用该规则并重写查询。以下是（可选）规则的详尽列表：
 视图合并：如果您在查询中使用视图，则视图将使用该视图的SQL代码进行转换。 子查询拼合：很难优化子查询，因此重写器将尝试使用子查询修改查询以删除子查询。 例如:  SELECT PERSON.* FROM PERSON WHERE PERSON.person_key IN (SELECT MAILS.person_key FROM MAILS WHERE MAILS.mail LIKE &#39;christophe%&#39;);  将被重写为：</description>
    </item>
    
    <item>
      <title>关系型数据库是怎么工作的5:基本组件之客户端管理</title>
      <link>/post/2018/01/02/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%845%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%AE%A1%E7%90%86/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/02/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%845%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6%E4%B9%8B%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%AE%A1%E7%90%86/</guid>
      <description>基本组件(前4节)  引言 时间复杂度 合并排序 数组.树.哈希表  我们刚介绍的是数据库内部的基本原理
数据库是一个可以轻松访问和修改的**信息的集合*。 但是一堆简单的文件也可以做到这一点。 实际上，最简单的数据库（如SQLite）仅是一堆文件。 但是SQLite是精心设计的一堆文件因为它可以: - 使用事务去确保数据安全和交易连续性 - 快速处理数据,即使是几百万行数据
通俗来说,数据库可以如下图所示
在写这部分前,我看了很多书和论文,不同的数据库对基础组件的称呼不同.所以不要关注我是怎么组织数据库理念的,也不要关注我是怎么给这些处理过程命名的.因为这篇文章的需要我做了一些取舍.忽略这些组件的差异;总的思路是将整个数据库系统分成以下几个组件:
核心组件:  进程管理器 : 很多数据库有个*进程/线程*池需要处理.此外，为了获得纳秒级的性能，某些现代数据库使用自己的线程管理而不是操作系统线程管理。 网络管理器 : 网络I/O是一个关键点，尤其是对于分布式数据库。 这就是为什么某些数据库拥有自己的管理器的原因 文件管理器 : 磁盘I/O是数据库最大(或者说是每一位)的瓶劲.拥有一个自身的文件管理理可以很好的的适配或替代操作系统文件管理器 内存管理器 : 为了避免磁盘I/O需要大量的内存.处理大量的内存你需要一个高效的内存管理器,尤其是你有很多查询同时用到内存的情况下 安全管理器 : 用于管理用户的身份验证和授权 客户端管理器 : 用于管理客户端的连接 &amp;hellip;&amp;hellip;  工具:  备份管理器 : 用于保存和还原数据库。。 恢复管理器 : 崩溃后以一致状态重新启动数据库 监视管理器 : 用于记录数据库的活动并提供监视数据库的工具 后台管理器 : 用于存储元数据（如表的名称和结构），并提供工具来管理数据库，模式，表空间，… &amp;hellip;&amp;hellip;  查询管理器：  查询解析器 ：检查查询是否有效 查询重写器 ：预优化查询 查询优化器 ：优化查询 查询执行器 ：编译并执行查询  数据管理器:  事务处理器 ：处理事务 缓存管理器 ：在使用数据之前先将其放入内存中，然后在将其写入磁盘之前先将其放入内存中 数据访问管理器 ：访问磁盘上的数据  在这篇文章的剩余部分,我将着重讲述一个数据库系统如何用下面三个过程来处理SQL查询的 - 客户端管理器 - 查询管理器 - 数据管理器(这里也会讲恢复管理器)</description>
    </item>
    
    <item>
      <title>关系型数据库是怎么工作的4:数组.树.哈希表</title>
      <link>/post/2017/09/12/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%844%E6%95%B0%E7%BB%84.%E6%A0%91.%E5%93%88%E5%B8%8C%E8%A1%A8/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/09/12/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%844%E6%95%B0%E7%BB%84.%E6%A0%91.%E5%93%88%E5%B8%8C%E8%A1%A8/</guid>
      <description>3.数组.树.哈希表 这一节讲数据结构。很重要，因为它是现代数据库的主心骨。在这一节，我还会介绍数据库索引的概念
3.1 数组 二维数组是一种最简单的数据结构，一个表可以看作是一个数组，例如：
这个二维数组是一张行和列组成的表：
 每行代表一个主题 这些列描述主题的功能 虽然可以很好地存储和可视化数据，但是当您需要查找特定值时，它会很糟糕。 例如：如果你想找到所有UK工作的人，你只能查找每一行去确定是不是有UK工作的，这将花费你N次操作（N=行数）,这也不太差但这里有更快的办法吗？这就是一会我们要说的&amp;rdquo;树&amp;rdquo;出现了。  Note: 大多数现代数据库都提供高级阵列来高效地存储表，例如堆组织表或索引组织表。 但这并不会改变在一组列上快速搜索特定条件的问题。
3.2 树和索引 二叉搜索树是一种有特殊属性的二叉树，每个节点中的key必须满足以下条件：
 必须大于所有存储在左侧子树中的key 必须小于所有存储在右侧子树中的key  让我们用图看看这个意思
这棵树有N=15个元素,我们来试试找 208
 我从根节点 136 开始. 因为136&amp;lt;208, 我需要在136的右子树上找. 398&amp;gt;208 因此, 我要找398的左子树 250&amp;gt;208 因此, 我要找250的左子树 200&amp;lt;208 因此, 我要找200的右子树. 但 200 并没有右子树, 这个KEY不存在 (因为如果它存在,它只能存在200的右子树上,现在没有)  我们来试试找 40
 我从根节点 136 开始. 因为136&amp;gt;40, 我需要在136的左子树上找. 80&amp;gt;40 因此, 我要找80的左子树 40= 40, 节点存在. 我提取出这个节点行id(图上没有显示ID)然后通过行id查找表 知道行ID后，我便知道数据在表上的确切位置，因此可以立即获取它。  最后,两个搜索都花费了*树的高度*次操作,如果你有认真阅读上一节中我们关于合并排序的内容 ,你应该明白这个值是 log(N).所以花费了long(N)次操作.还不错!
3.3 回顾下我们的问题 但是这个描述非常抽象,让我们回到我们的问题(上一小节中在表中查找UK工作的人). 同样是一棵树,不过这次不再是愚蠢的int型数字,而是一个代表国家的字符串.</description>
    </item>
    
    <item>
      <title>关系型数据库是怎么工作的3:合并排序</title>
      <link>/post/2017/09/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%843%E5%90%88%E5%B9%B6%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Mon, 11 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/09/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%843%E5%90%88%E5%B9%B6%E6%8E%92%E5%BA%8F/</guid>
      <description>2.合并排序 当需要排序一个集合时，你该怎么做？ 什么？ 你调用 sort()方法&amp;hellip;. 好吧，好答案&amp;hellip;但是对一个数据库来说，你需要弄明白这个sort()方法是怎么工作的.
这里有几种不错的排序算法，所以我这里重点说说这个最重要的算法：合并排序 你可能现在还不明白为啥对数据进行排序这么重要，在这篇文章后面的章节&amp;lt;查询优化&amp;gt;中会交待。 此外，了解合并排序将有助于我们理解后面的一个常用数据库操作：join ,因为它调用了合并排序
2.1合并 像许多有用的算法一样，合并排序基于一个技巧：将2个大小为N/2的已排序数组合并为N个元素的排序数组仅需要N次操作。 此操作称为合并。
让我们通过一个简单的例子来说明：
从上图上你可以看到，要想得到最终的已经排好序的8元素数组，你只需要迭代一次在两个有序的4元素数组中.
 比较两个数组的第一个元素(这里要想象一下两个数组都有个游标) 然后把最小的那个数放到8元素数组的第一个位置上 接着把游标顺着移走的数移到下一个位置上 重复1，2，3 动作，直到到达两个数组其中一个的终点。 然后把另一个数组里剩下的元素都放到8元素结果集中 这个排序的前题是原始的4元素数组是已经排序过的，所以你不需要在数组中做&amp;rdquo;go back&amp;rdquo; 操作  现在我们已经明白了合并排序的技巧了，这是我写的合并排序的伪码
array mergeSort(array a) if(length(a)==1) return a[0]; end if //recursive calls [left_array right_array] := split_into_2_equally_sized_arrays(a); array new_left_array := mergeSort(left_array); array new_right_array := mergeSort(right_array); //merging the 2 small ordered arrays into a big one array result := merge(new_left_array,new_right_array); return result;  合并排序把问题分解成更小的问题，然后这些通过解决小问题，得到初始问题的结果。(这种算法被称为：分而治之). 如果你不明白这种算法，不要着急，我一开始也不太明白，我们来尝试把这个算法拆成两阶段算法：
 分隔阶段 把数组分隔成更小的数组 排序阶段 把小的数组合并到一起（用合并）成一个大数组  2.</description>
    </item>
    
    <item>
      <title>关系型数据库是怎么工作的2:时间复杂度</title>
      <link>/post/2017/09/10/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%842%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/09/10/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%842%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/</guid>
      <description>1 O(1) vs O(n^2) 现如今，很多程序员不关心时间复杂度&amp;hellip;.好吧，他们是对的！
但当你处理大数据时（我不是说几千个）或者你为了几毫秒的性能在优化，就非常有必要了解这个理论了。刚巧，数据库符合这两种情况！ 不会花费太长时间，只是了解下，这将有助于我们理解后面说的&amp;rdquo;基于成本的优化&amp;rdquo;
1.1 时间复杂度概念 时间复杂度被用来表达算法处理已知问题所消耗的时长，为了表达这个复杂度，计算机科学家使用数学上的大O符号。 该符号加上算法需要进行多少次操作函数一起使用。
用下图来说明时间复杂度的差异 O(1) 是静态的 O(log(n)) 保持在一个低复杂度，哪怕有几十亿的数据要处理 O(n^2) 是复杂度最差的
1.2 时间复杂度举例 当数据量少的时候，O(1) 和 O(n^2) 之间的差异是微不足道的。 比如说，当你需要个算法处理2000条数据时
 O(1) 算法花费 1 次操作 O(log(n)) 算法花费 7 次操作 O(n) 算法花费 2000 次操作 O(n*log(n)) 算法花费 14000 次操作 O(n^2) 算法花费 4000000 次操作  看起来 O(1) 和 O(n^2) 算法好像差了4000000次倍的操作，但最多只多花了2毫秒，跟你眨一次眼睛一样的时间，现代的CPU进程每秒处理几亿次操作，这就是为什么性能和优化在IT项目中显得不那么重要.
正如我说的那样，当处理大量数据时，理解时间复杂度的概念还是非常重要的，这次我们试试处理 1000000条数据（一百万行对数据库来说并不多）
 O(1) 算法花费 1 次操作 O(log(n)) 算法花费 14 次操作 O(n) 算法花费 100万 次操作 O(n*log(n)) 算法花费 140万 次操作 O(n^2) 算法花费 10000亿 次操作  都不用去计算，这个糟糕的O(n^2) 算法足够你去喝杯咖啡了（甚至再来一杯）！如果再100万条数据后面再加一个0，那就足够你睡一小觉了。</description>
    </item>
    
    <item>
      <title>关系型数据库是怎么工作的1:引言</title>
      <link>/post/2017/09/09/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%841%E5%BC%95%E8%A8%80/</link>
      <pubDate>Sat, 09 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/09/09/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%841%E5%BC%95%E8%A8%80/</guid>
      <description>本文翻译自一篇法国作者的博客，觉得写得不错， 原文地址：http://coding-geek.com/how-databases-work/
说起关系型数据库，我总是认为少了点什么。 关系型DB几乎无处不在，有不同类型，从迷你但实用的SQLite到功能强大的Teradata。 但只有少数几个文章谈论这些关系型数据库的工作方式。
不信，你可以看看Google搜索“关系数据库如何工作”，只有很少的几条结果，且非常简短。 如果你搜索新的流行技术(Big Data, NoSQL or JavaScript),你会发现很多深入解释工作原理的文章
是不是关系型数据库太老了，以至于在大学课程、研究论文、书本以外的地方解释原理显得无聊。
作为一个开发者，我不能容忍我不明白的事情发生，而且 ，如果数据库技术已经被用了40年，这里一定有原因。这些年，我花了几百个小时去真正理解这些奇怪的我每天都用的黑盒子， 关系型数据库是非常有趣的因为他们基于有用的可复用的理念上，如果你有兴趣搞懂数据库，但是你没有时间或意愿去深入了解这个很宽泛的主题，那么你会喜欢这篇文章的。
标题已经说得很清楚了，这篇文章的上的不是为了让大家学会怎么用数据库。所以你应该已经知道怎么写一个简单的JOIN查询和基本的增删改查SQL，否则你可能无法理解这篇文章，这是你唯一需要了解的知识，其他的我来给你们讲解吧。
这是一篇很长的包括了很多算法和数据结果技术文章,将会花费你很长的时间去阅读，有些概念很难懂，你可以跳过它理解整体的思路。
为了你更容易理解，本文大约分成三个部分
 一些低阶或高阶的数据库理论(1-3节，包含在本篇文章中) 查询优化器进程（第4节） 事务和缓冲池管理（第5节）  以下是目录：
 基础知识  1.1 O(1) vs O(n^2)
 1.2 合并排序 1.3 数组，树，哈希表  通用概念 客户端管理 SQL查询  4.1 SQL解析 4.2 查询重写 4.3 统计信息 4.4 SQL优化 4.5 SQL执行  数据管理  5.1 缓存管理 5.2 事务管理  总结  在很远很远的远古时期,码农们需要准确知道他们编写的代码是怎么运行的。他们心里知道他们的算法和数据结构，因为他们不能浪费一点点他们那些破电脑的一点点CPU和内存。
在这个章节，我将带大家回顾这些概念，因为这对弄懂数据库很关键，顺便我还会介绍索引的概念
本节完成，下一章节我们将讨论：时间复杂度
本篇文章完整分为7节，当前第1节。以下完整章节：
 引言 时间复杂度 合并排序 数组.树.哈希表 客户端管理 SQL查询 数据管理  </description>
    </item>
    
  </channel>
</rss>