<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ais on Classic</title>
    <link>/ai/</link>
    <description>Recent content in Ais on Classic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 07 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2000元就能本地部署AI大模型？7种DeepSeek配置对比</title>
      <link>/ai/deepseek%E6%9C%AC%E5%9C%B0%E5%8C%96%E5%AE%89%E8%A3%85%E4%BD%A0%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>/ai/deepseek%E6%9C%AC%E5%9C%B0%E5%8C%96%E5%AE%89%E8%A3%85%E4%BD%A0%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B/</guid>
      <description>《DeepSeek R1的低成本奇迹——557万美元如何改变AI行业？》
 DeepSeek火出圈的原因有两个：一是强大的推理能力，二是廉价的成本 目前为止DeepSeek是最省显卡的AI模型 随着官方的DeepSeek服务器被用户挤爆。 经常会遇到：服务器繁忙，请稍后再试。严重影响使用 这时候就会有些聪明人想：能不能在自己的电脑上安装一个私人的DeepSeek，只给自己提供访问 答案是：可以的 那多少钱的电脑可以跑动一个私有的AI大模型呢 答案是：最低配置是2000块钱的台式电脑就可以！  访问DeepSeek的几种方法 方法1: 访问DeepSeek官网 通过DeepSeek的官方网站，用户可以在线使用DeepSeek模型进行各种任务，无需安装任何本地软件。
方法2: 下载DeepSeek手机APP 用户可以通过手机APP访问DeepSeek，随时随地使用模型进行任务。
方法3: 本地安装DeepSeek服务 用户可以在本地计算机上安装DeepSeek服务，直接在本地使用模型进行计算和任务处理。
三种访问方式的对比：    特征 访问DeepSeek官网 手机APP 本地DeepSeek     成本 免费 免费 需要硬件资源和安装费用   易用性 容易 容易 较难   数据存储 云端 云端 本地   隐私保护 取决于厂商 取决于厂商 最大隐私保护   更新与维护 自动更新 自动更新 需手动更新   计算资源 依赖厂商 依赖厂商 取决于本地硬件配置     方法1（访问官网）：日常办公或在家有电脑 方法2（手机APP）： 拿着手机出门移动办公或在家使用。 方法3（本地安装服务）：适合需要处理敏感数据或高性能需求的用户，但需要一定的技术知识，并且受限于本地硬件的性能和更新维护。  哪些职业的人需要部署本地AI 在涉及到敏感数据和隐私保护的职业中，很多从业人员更倾向于使用本地部署的AI系统，以确保数据安全。以下是一些更适合访问本地AI的职业：</description>
    </item>
    
    <item>
      <title>英伟达黄仁勋20250107CES主题演讲（全文）</title>
      <link>/ai/%E8%8B%B1%E4%BC%9F%E8%BE%BE%E9%BB%84%E4%BB%81%E5%8B%8B20250107ces%E4%B8%BB%E9%A2%98%E6%BC%94%E8%AE%B2%E5%85%A8%E6%96%87/</link>
      <pubDate>Tue, 07 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%8B%B1%E4%BC%9F%E8%BE%BE%E9%BB%84%E4%BB%81%E5%8B%8B20250107ces%E4%B8%BB%E9%A2%98%E6%BC%94%E8%AE%B2%E5%85%A8%E6%96%87/</guid>
      <description>北京时间1月7日（周二）上午，英伟达创始人兼CEO黄仁勋在拉斯维加斯举行的CES 2025大会上发表开幕主题演讲。 现场，黄仁勋宣布推出包括售价高达1999美元的RTX 5090显卡在内的一系列全新产品。黄仁勋称，这款新显卡将成为英伟达游戏芯片业务的支柱。 除了RTX50系列显卡外，黄仁勋还发布了多款“王炸”，包括语言基础模型Llama Nemotron和世界基础模型Cosmos。开放式Llama Nemotron大型语言模型和Cosmos视觉语言模型可在任何加速系统上为AI代理提供超级动力。 同时，黄仁勋预告，将于5月推出一款名为Project Digits的个人AI超级计算机，其核心是新的GB10 Grace Blackwell超级芯片，它具有足够的处理能力来运行复杂的AI模型，仅需标准电源插座即可运行。 此外，黄仁勋宣布推出下一代汽车处理器Thor，这是一款革命性的机器人计算机，旨在处理大量传感器数据。他还表示，丰田和英伟达将合作开发下一代自动驾驶汽车。
 欢迎来到CES！ 你们兴奋地来到拉斯维加斯吗？ 你们觉得我的夹克怎么样？ 我想我可以和Shapiro（CES总裁）的风格有所不同。 毕竟我在拉斯维加斯。 如果你们都不喜欢，那就忍着吧。 我真的觉得你们需要消化一下。 因为再过1个小时左右，我会让你们满意。
欢迎来到NVIDIA，我们将带您领略NVIDIA的世界。 女士们、先生们，欢迎来到NVIDIA。
这里的一切都是由人工智能生成的。 这是一个非凡的旅程，也是一个非凡的年份，始于1993年。 通过NV1，我们希望构建能够执行普通计算机无法完成的任务的计算机。 NV1使得在您的个人电脑上拥有成为游戏主机的能力。
我们的编程架构名为UDA，直到不久之后才有了字母C，但UDA，统一设备架构。第一个为UDA开发的应用程序是世嘉的《VR战士》。六年后，在1999年我们发明了可编程GPU。这开启了超过20年的惊人进步，GPU这一神奇的处理器让现代计算机图形成为可能。现在，30年后，世嘉的《VR战士》已经完全电影化。这是即将推出的新《VR战士》项目。我迫不及待地想看到它，绝对令人难以置信。六年之后，UDA诞生了。
在1999年后的六年里，我们发明了CUDA，以便能够向一系列能够从中受益的算法解释或表达我们GPU的可编程性。最初，CUDA很难解释，实际上花费了多年时间，大约六年。无论如何，大约六年后，也就是在2012年，Alex Kershevsky、Ilya Suskovor和Jeff Hinton发现了CUDA，并用它来处理AlexNet（一个卷积神经网络），接下来的发展便成为了历史。从那时起，人工智能以惊人的速度发展。起初是感知AI，现在我们能够理解图像、文字和声音，走向生成式AI。
现在我们谈论的是代理性AI，也就是那些能够感知、推理、计划并采取行动的AI。
接下来是下一阶段，即物理AI，这也是我们今晚将讨论的一部分，它始于2012年。然后在2018年，神奇的一年里，发生了一件令人难以置信的事情。谷歌发布了Transformer模型的BERT，自此AI领域真正迎来了腾飞。正如大家所知，Transformers彻底改变了人工智能的格局。事实上，它甚至彻底改变了整个计算领域的格局。我们深刻认识到，AI不仅仅是一个新应用领域或新的商业机会，更重要的是，由Transformers驱动的机器学习，将从根本上改变方式。
计算在每一个层面上都发生了革命性变化，从手动编码指令以运行在CPU上的软件工具，到我们现在拥有的可以创建和优化神经网络并在GPU上进行处理的机器学习，从而生成人工智能。技术堆栈的每一个层面都已经完全改变，这在过去12年中是一次令人难以置信的变革。现在，我们能够理解几乎任何形式的信息。你们肯定见过文本、图像和声音等内容，但我们不仅能理解这些，我们还能理解氨基酸，理解物理。我们不仅理解它们，还能够翻译和生成它们。
应用的可能性几乎是无穷无尽的。事实上，市场上几乎所有的AI应用，都是通过什么样的输入模态学习而来的？它又把什么样的信息模态转换成了什么，最终生成了什么样的信息模态？如果你问这三个基本问题，几乎每个应用都可以得到推断。因此，当你看到一个又一个以AI驱动、以AI为本质的应用时，这一基本概念必然存在。机器学习改变了每一个应用的构建方式，改变了计算的方式，以及超越这些的可能性。正如GeForce GPU，在很多方面，所有这些与AI相关的成就都是GeForce所建立的。GeForce使得AI能够惠及大众。那么，现在呢？人工智能回归GeForce。 许多事情没有人工智能是无法完成的。现在让我给你展示其中的一部分。
……（宣传片）
没有任何计算机图形研究者或计算机科学家会告诉你这是可能的。
我们可以为每一个像素进行光线追踪。光线追踪是光的模拟。你看到的几何形状数量绝对惊人。如果没有人工智能，这一切都是不可能的。我们做了两件根本性的事情。我们当然使用了可编程着色和光线追踪加速，产生了极其美丽的像素。然后，我们让人工智能根据那个像素进行调节和控制，以生成大量其他像素。它不仅能够在空间上生成其他像素，因为它知道颜色应该是什么，而且它是在 NVIDIA 的超级计算机上进行训练的。因此，运行在GPU上的神经网络能够推断和预测我们没有渲染的像素。不仅如此，这被称为DLSS（超分辨率技术）。
最新一代的DLSS不仅仅是生成帧。它还能预测未来，为每一帧计算生成三个额外的帧。你看到的，如果我们只是说你看到的四帧，因为我们将渲染一帧并生成三帧。如果我说四帧在全高清和4K下，那就是大约3300万个像素。在这3300万个像素中，我们只计算了两个。能够计算出200万个像素，并让人工智能预测其余的3300万个像素，简直是个绝对的奇迹。结果，我们能够以令人难以置信的高性能进行渲染，因为人工智能的计算量大大减少。
当然，这需要大量的训练才能实现，但一旦训练完成，生成过程极其高效。因此，这是人工智能的一项令人难以置信的功能，这也是为什么有如此多惊人的事情正在发生。我们利用GeForce推动人工智能的发展，而如今人工智能又在革命GeForce。
今天我们宣布我们的下一代产品，RTX Blackwell系列。让我们来看看。
这是我们最新基于Blackwell架构的全新GeForce RTX 50系列显卡。这是一款性能野兽，搭载920亿个晶体管，4000 AI TOPS，是以前Ada的3倍。这都是我刚刚展示的画面所必需的硬件。
我们拥有380个光线追踪的太浮点运算能力，以便为我们必须计算的像素提供尽可能美丽的图像。当然，还有125个着色器的太拉浮点运算能力。实际上，除了并行着色器的泰拉浮点运算能力之外，还有一个整数单元，性能相等。因此，有两个双重着色器，一个用于浮点运算，另一个用于整数运算。来自美光的G7内存，速度为每秒1.8TB，是我们上一代产品性能的两倍。
我们现在有能力将AI工作负载与计算图形工作负载混合处理。这一代产品最令人惊讶的地方是，可编程着色器现在也能处理神经网络。因此，这个着色器能够承载这些神经网络，从而我们发明了神经纹理压缩和神经材料着色。由此产生的，是无法仅靠传统技术实现的令人惊叹的美丽图像，因为我们运用了AI技术学习纹理，学习压缩算法，最终获得卓越的结果。
好的，这就是全新的RTX Blackwell 50系列。甚至连机械设计都是一个奇迹。看看这个，它有两个风扇。整个显卡就像是一个巨大的风扇。那么问题来了，显卡在哪里？它真的这么大吗？电压调节器的设计达到了最先进水平。令人难以置信的设计。工程团队做得非常出色。
那它和之前的相比如何呢？这就是RTX 4090，价格是1599美元。这是你能做出的最好的投资之一。花1599美元，你可以把它带回家，搭配你的10000美元的PC娱乐指挥中心。不是吗？别告诉我这不是真的。它是液冷的，四处都有华丽的灯光。如果说这就是现代家庭影院完全说得通。
而现在，花1500美元到1599美元，你就可以对它进行升级，并为它注入强大的动力。现在，随着Blackwell家族的到来，RTX 5070拥有4090的性能，仅售549美元。5090的性能是4090的两倍。我们将于1月开始大规模生产，当然，产品将很快上市。
这是令人难以置信的，但我们成功地将这些巨大的高性能GPU放入了一台笔记本电脑。这是一台5070笔记本电脑。价格为1299美元的5070笔记本具有4090的性能。我想这里有一个。让我给你展示一下。你能想象吗，你拥有这个令人惊叹的显卡，Blackwell，我们将把它缩小并放入笔记本中，不利用我们的人工智能你是做不到的。原因是我们通过我们的核心生成大部分像素。因此，我们只追踪所需的像素，其他像素则由人工智能生成。结果是，能效简直是天文数字。计算机图形的未来是神经渲染，人工智能的融合。
5090显卡将能够融入到一款薄型笔记本电脑中，那款电脑厚度在14.9毫米。我们还有5080、5070 Ti和5070。那么，女士们，先生们，这就是RTX Blackwell系列。
GeForce将人工智能带入了世界，实现了人工智能的普及，而如今人工智能又回过头来彻底改变了GeForce。
让我们谈谈人工智能，接下来我们来到NVIDIA的另一处地方。这确实是NVIDIA的总部。好吧，让我们深入讨论一下人工智能行业。整个行业一直在追逐和竞相扩展人工智能，而扩展法则则是一个强大的模型，它是一个经验法则，已经在多个世代的研究者和行业中被观察和证明。扩展法则表明，你拥有的训练数据越多，模型越大，应用的计算能力越强，因此你的模型将变得更加有效或更强大。因此，扩展法则依然适用。令人惊奇的是，我们现在正在迈向新的阶段。
当然，互联网每年产生的数据量几乎是去年的两倍。我认为在未来几年内，人类将产生的数据量将超过人类自古以来所产生的总数据。因此，我们依旧在产生海量数据，而且这些数据正变得多模态。视频、图像和声音，这些数据都可以用于训练人工智能的基础知识和基本知识。但实际上，现在出现了另外两个扩展法则，这些法则也颇具直观性。第二个扩展法则是后训练扩展法则。后训练扩展法则利用强化学习、人类反馈等技术和方法。基本上，人工智能会生成和产生答案。
基于人类查询，而人类给出反馈。虽然这要复杂得多，但这个强化学习系统通过大量高质量的提示使得人工智能不断提升其技能。它可以在特定领域进行技能微调，能更好地解决数学问题，更好地进行推理，等等。因此，这本质上就像是有一个导师或教练在你学习结束后给予反馈。你会接受测试，得到反馈，不断改善自己。我们还有强化学习的人工智能反馈和合成数据生成。这些技术就类似于自我练习。你知道某一特定问题的答案，并不断尝试直到获得正确答案。</description>
    </item>
    
    <item>
      <title>微调有必要做吗？微调还是RAG?</title>
      <link>/ai/%E5%BE%AE%E8%B0%83%E6%9C%89%E5%BF%85%E8%A6%81%E5%81%9A%E5%90%97%E5%BE%AE%E8%B0%83%E8%BF%98%E6%98%AFrag/</link>
      <pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%BE%AE%E8%B0%83%E6%9C%89%E5%BF%85%E8%A6%81%E5%81%9A%E5%90%97%E5%BE%AE%E8%B0%83%E8%BF%98%E6%98%AFrag/</guid>
      <description>我需要对大模型做微调吗？ 想自定义大模型时，选择：微调还是RAG还是ICL？   需要对大模型做微调？  在人工智能的世界里，大型语言模型（LLM）已经成为了我们探索未知、解决问题的得力助手。 但是你想自己定义一个属于自己的大模型，它有自己特色的数据训练和回答方式。自己从头训练一个大模型的成本太高 这时候可能需要考虑在已有的大模型上做：微调 就像一个微整容手术一样，变得更帅     判断因素 是 否     是否需要特定领域的精确性？ 如果你的应用需要处理特定领域的数据，如医疗、法律或金融，并且需要高度的准确性和对专业术语的理解，那么微调可能是必要的。 如果你的应用是通用的，或者不需要深入特定领域的专业知识，那么可能不需要微调。   是否需要定制化模型行为？ 如果你需要模型以特定的风格、语调或格式响应，或者需要它表现出特定的行为特征，微调可以帮助你实现这些定制化需求。 如果模型的通用行为已经满足需求，或者你不需要特定的响应风格，那么微调可能不是必需的。   是否面临边缘案例的挑战？ 如果你发现模型在处理某些边缘或罕见案例时表现不佳，微调可以帮助改进这些特定情况的处理。 如果模型在所有常见和边缘案例中都表现良好，那么微调可能不是必要的。   是否需要提高模型的可靠性？ 如果模型在遵循复杂指令或生成期望输出方面存在失败，微调可以提高其可靠性。 如果模型已经足够可靠，能够满足你的输出要求，那么可能不需要微调。   是否需要降低成本？ 如果你希望通过微调将大型模型的技能转移到更小的模型中，以减少计算资源的使用和成本，那么微调是有益的。 如果成本不是主要考虑因素，或者你不需要优化模型的大小和性能，那么微调可能不是必需的。   是否需要快速部署新任务？ 如果你需要模型快速适应新任务或能力，微调可以帮助你实现这一点。 如果模型目前的任务已经足够，并且没有立即引入新任务的需求，那么微调可能不是必要的。   是否有足够的训练数据？ 如果你拥有足够的、高质量的、与任务相关的训练数据，微调可以显著提高模型的性能。 如果缺乏足够的训练数据，或者数据质量不高，微调可能不会带来预期的效果。   是否对模型的透明度有要求？ 如果你的应用需要模型的决策过程是可解释的，微调可以帮助你更好地理解和控制模型的行为。 如果模型的透明度不是关键考虑因素，那么可能不需要微调。   是否有足够的资源进行微调？ 如果你有足够的计算资源和专业知识来进行微调，那么这是一个可行的选项。 如果资源有限，可能需要考虑其他方法，如上下文学习或使用现成的模型。    1. 定制化风格与格式 你是否需要一个能够模仿特定人物或服务于特定受众的聊天机器人？通过使用定制数据集对LLM进行微调，我们可以使其响应更加贴近受众的具体要求或预期体验。例如，你可能需要将输出结构化为JSON、YAML或Markdown格式。</description>
    </item>
    
    <item>
      <title>用ai技术来帮普通人完成扣篮</title>
      <link>/ai/%E7%94%A8ai%E6%8A%8A%E7%85%A7%E7%89%87%E5%8F%98%E6%88%90%E8%A7%86%E9%A2%91%E6%95%88%E6%9E%9C%E6%83%8A%E4%BA%BA/</link>
      <pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E7%94%A8ai%E6%8A%8A%E7%85%A7%E7%89%87%E5%8F%98%E6%88%90%E8%A7%86%E9%A2%91%E6%95%88%E6%9E%9C%E6%83%8A%E4%BA%BA/</guid>
      <description> 上周朋友给我拍了一张打篮球的照片 当时我想表演一下扣篮 奈何弹跳能力有限 只留一下朴素的照片 好在有ai技术 弥补了老年人跳不起来的尴尬  原片（照片） 成片（视频）   </description>
    </item>
    
    <item>
      <title>AI的电力需求以及国内的电力能源情况</title>
      <link>/ai/%E8%83%BD%E6%BA%90%E4%B8%8Eai/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%83%BD%E6%BA%90%E4%B8%8Eai/</guid>
      <description>AI的惊人耗电量  当我们说大模型AI的使用成本很贵的时候 一方面其训练和推理的硬件GPU本身很贵，另一方面其消耗的电力也很夸张 这里我们只说AI的耗电量  AI训练阶段耗电量  OpenAI的GPT-3模型一次训练的耗电量高达1287兆瓦时 谷歌于2022年发布的大语言模型PaLM一次训练需要消耗3436兆瓦时的电量 模型越大，训练所需要消耗的电量越多。现在gpt-4o,文心一言4,通义千问这些新的大模型训练用电量会更夸张  AI推理阶段的耗电量  GPT每生成1000个英文单词大约消耗0.125千瓦时的电量 OpenAI需要3,617台英伟达公司的HGX A100服务器（共有28,936个图形处理单元 (GPU)）来支持 ChatGPT，这意味着每天的能源需求为 564 兆瓦时 谷歌搜索中应用生成式AI技术，谷歌每年的耗电量将高达290亿千瓦时，也就是每天约7900万度电  AI耗电的原因及改进方向 AI耗电的原因：GPU运算   以H800 GPU PCIE 服务器整机为例：
 CPU耗电约 300W*2， 内存16根耗电约 250W 硬盘6块盘约200W 风扇耗电约150W H800GPU卡耗电约700W*8    合计：最大耗电量约为6800W（90%以上的耗电都是GPU引起的）
  这些还不包括机房空调制冷的电力消耗
    这样的一台服务器，对OpenAI这样的公司来说，一个机房里需要放几万台
  AI耗电的改进方向  随着英伟达的GPU工艺不停的迭代发展 每次英伟达的新品发布会，都会发现新一代的显卡比上一代的能耗是几倍的减少 性能越来越高，单位算力的能耗成倍的减少，这是实大实的在减少能耗 可惜AI的算力要求越来越高，减少的能耗目前赶不上需求的增长 未来很长一段时间AI消耗的能源会越来越多。  国内电力能源现状  来自国家能源局发布的《2023年全国电力工业统计数据》 太阳能和风能装机量正在快速增长     类别 装机容量(万千瓦时) 占比 同比增长     火电 139032 47.</description>
    </item>
    
    <item>
      <title>利用开源大语言模型打包成自己的大语言模型</title>
      <link>/ai/%E5%88%A9%E7%94%A8%E5%BC%80%E6%BA%90%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%89%93%E5%8C%85%E6%88%90%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sun, 28 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%88%A9%E7%94%A8%E5%BC%80%E6%BA%90%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%89%93%E5%8C%85%E6%88%90%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</guid>
      <description>为什么要用开源模型 大语言模型有两种类型：  闭源的模型，如GPT-3.5、GPT-4、Cluade 、文心一言等 开源的模型，如LLaMA、ChatGLM,Qianwen等  开源模型的优势  已知目前最强的gpt4等大模型是商用闭源的，这些模型参数更大，更加智能，为什么我们会关注开源模型呢？ 可以本地部署运行（利用自己的电脑或服务器，运行）数据交互不需要和外网连接，数据安全性提升 不需要购买服务，不用开会员，跑在自己的电脑上，想用多少就用多少   怎么打包自己的模型 本地运行大模型  本地运行，需要至少一台性能很好的机器，不管是服务器，云服务器，或者自己的电脑，最好有张naviad 的显卡 选择大模型，现在目前最好的是llama3 是由Meta公司开源的，另外gemma是Google的，也非常不错，微软和苹果也开源了。中文的阿里开源的千问也不错 选好大模型后去下载到本地（体积看参数多少，在4G&amp;ndash;100G之间） 下载好后，就可以本地运行了，只需要在命令行中输入命令 如果想要个网页端上对话，可以再下载一个网页端，比如open webui （这是我喜欢用的）。看个人风格  打包自己的模型  有个新闻说是国内现在发布了几百个ai大语言模型，很多都是基于这些开源的模型上训练或改的 即使在开源模型上训练和微调也需要很多的显卡资源和算力。也不是个人可以做到的 如果你和我一样没有很大算力的服务器，又想尝试发布自己的大模型 可以考虑重新打包一个大模型，让它变成你的大模型  怎么打包  步骤1.下载开源模型  wget &amp;quot;https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat-GGUF-8bit/blob/main/Llama3-8B-Chinese-Chat-q8.gguf&amp;quot;&amp;quot; ll -h -rw-r--r-- 1 root root 8.0G Apr 21 10:21 Llama3-8B-Chinese-Chat-q8.gguf -rw-r--r-- 1 root root 662 Apr 21 14:57 Modelfile  步骤2.编辑Modelfile  vim Modelfile #类型如下 FROM &amp;quot;/data/gguf/Llama3-8B-Chinese-Chat-q8.gguf&amp;quot; TEMPLATE &amp;quot;&amp;quot;&amp;quot;{{ if .</description>
    </item>
    
    <item>
      <title>国内大语言模型现状之法律篇</title>
      <link>/ai/%E5%9B%BD%E5%86%85%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%8E%B0%E7%8A%B6%E4%B9%8B%E6%B3%95%E5%BE%8B%E7%AF%87/</link>
      <pubDate>Tue, 23 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%9B%BD%E5%86%85%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%8E%B0%E7%8A%B6%E4%B9%8B%E6%B3%95%E5%BE%8B%E7%AF%87/</guid>
      <description>发展时间线  2022年11月30日,国外OPenAI公司的ChatGPT发布，大语言模型开始普及 2023年2月，国内ChatGPT开始进入国内视野大量媒体报道 2023年5月开始，基于开源ai大语言模型上用国内的法律条文和案例训练的国产法律大模型开始发布（以高校为主） 2023年底。随着llama模型升级，国产法律大模型更加智能，同时商业化落地产品开始出现 2024年由案例检索，合同审查为典型应用场景的国内法律AI产品开始推广应用  国内法律大语言模型现状    国内法律行业的大语言模型对比    大模型名称 日期 发布人 基础模型 推荐指数     ChatLaw 2023-06-28 北京大学深圳信息工程学院 Anima-33B 4星   LaWGPT 2023-04-12 南京大学 LLaMA 4星   LexiLaw 2023-05-16 清华大学 ChatGlM 6B 2星   獬豸(LawGPT_zh) 2023-04-09 上海交通大学 ChatGlM 6B 3星   Lawyer LLaMA 2023-04-13 北京大学 LLaMA 2星   韩非(HanFei) 2023-05-30 香港中文大学 LLaMA 1星   lychee_law-律知 2023-07-13 德国萨尔大学,中国南京大学 GLM-10B 1星   智海-录问 2023-08-08 浙江大学,ali达摩院,华院计算 Baichuan-7B 1星   DISC-LawLLM 2023-09-26 复旦大学 Baichuan-13B-Base 1星   夫子•明察 2023-08-31 山东大学,浪潮云,中国政法大学 ChatGLM 1星    国内法律大模型介绍 ChatLaw-法律大模型  地址：https://github.</description>
    </item>
    
    <item>
      <title>斯坦福大学发布了《2024人工智能指数报告》</title>
      <link>/ai/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E5%8F%91%E5%B8%83%E4%BA%862024%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8C%87%E6%95%B0%E6%8A%A5%E5%91%8A/</link>
      <pubDate>Tue, 16 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E5%8F%91%E5%B8%83%E4%BA%862024%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8C%87%E6%95%B0%E6%8A%A5%E5%91%8A/</guid>
      <description>今天斯坦福大学发布了《2024人工智能指数报告》  原文在这里，一共有500多页pdf https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf 我将一些感兴趣的点总结出来  AI的发展状况 AI在2023年的恐怖的发展速度  2023年，有GPT4,Cluade2,DALL-E3，Gemini等非常有突破性的产品发布 以下是15个重要的大模型的发布时间点，这些大模型一定程度上代表了当前AI能达到的最佳水平   AI大模型的发布时间  横轴是发布时间（2012-2024） 纵轴是发布时的计算量（Training compute (petaFLOP - log scale)）   高昂的训练成本  谷歌的 Gemini Ultra 的训练计算成本估计为 1.91 亿美元 OpenAI 的 GPT-4 的训练成本估计为 7800 万美元。 高昂的训练成本使普通用户（甚至包括学术机构和政府）难以参与AI的训练。   不同地区分展的速度不同 大语言AI模型发布数量  美国在2023 年总共开发了 61 个模型。 中国在2023 年总共开发了 8 个模型。   AI领域的投资  2023年，美国投资额为672亿美元 是第二高国家中国投资额的8.7倍 是英国投资额的17.8倍。 缩小范围来看，这一阵容看起来是一样的：自 2013 年以来，美国的累计投资额为 3,352 亿美元，其次是中国，为 1,037 亿美元，英国为 223 亿美元。   </description>
    </item>
    
    <item>
      <title>Ollama的安装和配置</title>
      <link>/ai/ollama%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/ollama%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</guid>
      <description>为什么要用Ollama  几乎是最方便的本地部署Ai大模型的方式 支持在 Mac、Windows、Linux 上运行 支持CPU,GPU 不用考虑复杂的本地环境 简直是大模型里的docker   Ollam官网的介绍是：Get up and running with large language models, locally.
 安装Ollla Mac  一行命令brew install ollama  Linux  一行命令  curl -fsSL https://ollama.com/install.sh | sh  Windows  下载ollama的安装包，下载地址 https://ollama.com/download/OllamaSetup.exe 安装上就即可  启动  ollama serve 启动服务 ollama list 查看本地的模型 ollama run 启动模型  配置Ollama 设置服务  vim /etc/systemd/system/ollama.service  [Unit] Description=Ollama Service After=network-online.target [Service] Environment=&amp;quot;OLLAMA_HOST=0.0.0.0:11434&amp;quot; ExecStart=/usr/local/bin/ollama serve #User=ollama #Group=ollama User=root Group=root Restart=always RestartSec=3 Environment=&amp;quot;PATH=/root/anaconda3/bin:.</description>
    </item>
    
    <item>
      <title>Sora来袭：OpenAI公司是否又开启文本生成视频新篇章？</title>
      <link>/ai/sora%E6%9D%A5%E8%A2%ADopenai%E5%85%AC%E5%8F%B8%E6%98%AF%E5%90%A6%E5%8F%88%E5%BC%80%E5%90%AF%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%A7%86%E9%A2%91%E6%96%B0%E7%AF%87%E7%AB%A0/</link>
      <pubDate>Tue, 20 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>/ai/sora%E6%9D%A5%E8%A2%ADopenai%E5%85%AC%E5%8F%B8%E6%98%AF%E5%90%A6%E5%8F%88%E5%BC%80%E5%90%AF%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%A7%86%E9%A2%91%E6%96%B0%E7%AF%87%E7%AB%A0/</guid>
      <description>Sora来袭  2024年2月15日OpenAI公司在推上连续发了几个Sora文生图视频，引起轰动 OpenAI并未单纯将其视为视频模型，而是作为“世界模拟器” Sora继承了DALL-E 3的画质和遵循指令能力 可以根据用户的文本提示创建逼真的视频 可以深度模拟真实物理世界，能生成具有多个角色、包含特定运动的复杂场景 能理解用户在提示中提出的要求，还了解这些物体在物理世界中的存在方式。  Sora来袭的反应  360集团创始人、董事长 周鸿祎   Sora将缩短AGI（通用人工智能）实现时间，从10年缩短到1年。OpenAI训练该模型应该会以视频和摄像头捕捉的画面为主，人工智能通过观看大量视频将对世界有更深入的理解，这离AGI实现不远
  电影导演兼视觉效果专家 迈克尔·格雷西   很快，像Sora这样的人工智能工具将允许电影制作者仔细控制他们的输出，从头开始创建各种视频，当技术剥夺了其他人的创造力、工作、想法和执行力，却没有给予他们应有的荣誉和经济报酬时，不是一件好事情。
  英伟达科学家 DrJimFan   Sora是一个数据驱动的物理引擎，它是对许多世界的模拟，无论是真实的还是幻想的，模拟器通过一些去噪和梯度数学来学习复杂的渲染、“直观”物理、长期推理和语义基础。
 Sora的团队  Sora核心团队有15人 Sora团队的Leader是Aditya Ramesh：他也是DALLE、DALLE2、DALLE3的主要作者 Sora的核心作者是Bill Peebles和Tim brooks Bill Peebles 在伯克利人工智能研究所完成了博士学位，导师是Alyosha Efros。在此之前，他在麻省理工学院攻读本科，指导老师是Antonio Torralba。他曾在FAIR、Adobe研究院和NVIDIA实习。 Tim brooks 在伯克利人工智能研究所获得了博士学位，导师是Alyosha Efros，他是InstructPix2Pix的作者。在此之前他曾在谷歌工作，参与Pixel手机相机的研发，在NVIDIA从事视频生成模型的研究。   Bill Peebles的说法是“每天基本不睡觉，高强度工作了一年。  如何试用Sora  答案是：现在还不行 到目前为止(北京时间 2023-02-20 18:20) Sora并没有对外开放 目前只有OpenAI内部员工,一批受邀请的视觉艺术家、设计师和电影制作人获得了Sora访问权限，他们也已开始在社交平台不断晒出使用Sora生成的新作品 未来开放时间不确定，但是首批可使用的用户数量不会太多，且肯定不会对中国大陆开放使用 国内用户要新手体验sora的功能，可能还是还很远  Sora的竞争对手    AI 公司 AI视频产品 发布日期      英伟达 PYoCo 2023.</description>
    </item>
    
    <item>
      <title>AIGC在哔哩哔哩内部的使用场景探索</title>
      <link>/ai/aigc%E5%9C%A8%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E5%86%85%E9%83%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/aigc%E5%9C%A8%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E5%86%85%E9%83%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E6%8E%A2%E7%B4%A2/</guid>
      <description> 2023年11月24日 系统架构师大会在上海举行 其中有一场b站OTT&amp;amp;漫画技术部邬晶的分享 《大模型与AIGC 在B站OTT、漫画业务中的应用探索》 分享中提到AIGC在哔哩哔哩内部的使用场景探索 包括以下几个场景的尝试  客服助手  编码助手 漫画辅助创作 辅助内容处理 合同格式化 辅助本地化      我感兴趣的有：客服助手，合同格式化  AI客服助手 背景：  客服侧同学需要同时处理多个业务线，每条业务线也一直处 于高速迭代状态，业务细节多，用户问题杂，为了帮助客服 同学提高问题处理效率，我们基于ChatGPT3.5输出了智能客服系统  解决方案 挑战 收益 拦截率:88.5% -&amp;gt; 92% 节省人力:13%
AI合同格式化 背景： 解决方案 挑战 收益  目前还在开发进行中 目标: 将合同电子化、平台化。各种权利项平滑入库，提升可维护性。降低商务成本。  小结  已完成的AI客服助手方案 是比较现实的可以落地的解决方案 也就是利用向量数据库来做关联匹配 实际运行中遇到的挑战 也是做此类产口需要关注的 这个分享说得非常具体了 合同格式化的是件收益不错的事B站也在开发中  </description>
    </item>
    
    <item>
      <title>DeepSeek</title>
      <link>/ai/deepseek%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E5%8C%85%E6%95%B4%E7%90%86%E6%89%93%E5%8C%85%E4%B8%8B%E8%BD%BD/</link>
      <pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/deepseek%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E5%8C%85%E6%95%B4%E7%90%86%E6%89%93%E5%8C%85%E4%B8%8B%E8%BD%BD/</guid>
      <description>在工作和生活中，撰写文案常为刚需。以下是我使用DeepSeek的一些技巧和文案范例，助你高效应对文案需求。
一、DeepSeek使用技巧  关键词设置：精准设置关键词可获取更符合需求的文案结果。 模板功能：利用模板快速构建文案框架，节省时间。  二、Deepseek指令合集  涵盖营销推广、 产品介绍、 活动邀请等多场景，为文案撰写提供灵感参考。 借助这些技巧和范例，大家能更好地运用DeepSeek提升文案撰写能力。  三、视频教程  如何利用国内现有平台做方案创作的视频教程，看看就好   以下这些资料都是网上公开渠道收集整理，非原创。
 ├─DeepSeek使用技巧 │ └─有用的，建议看 │ GenAI：国内外AI细分赛道与产品分析（198页）.pdf │ GenAI：国内外AI细分赛道与产品分析（198页）.pptx │ 浙江大学：2025年DeepSeek行业应用案例集解锁智能变革密码（153页PPT）.pdf │ 入门教程：DeepSeek 15天指导手册（25页word).pdf │ 北京大学：DeepSeek系列-DeepSeek与AIGC应用（99页PPT）.pdf │ 北京大学：DeepSeek系列-提示词工程和落地场景（86页PPT）.pdf │ 尚硅谷教育：deepseek-r1论文-中文翻译版（14页word).pdf │ 清华大学第三版：DeepSeek+DeepResearch：让科研像聊天一样简单（86页PPT）.pdf │ 清华大学第二版：DeepSeek赋能职场（36页PPT）.pdf │ 清华大学第一版：DeepSeek：从入门到精通（104页PPT）.pdf │ 尚硅谷教育：第三方平台-硅基流动部署DeepSeek R1（10页word）.pdf │ 尚硅谷教育：本地算力部署DeepSeek详细流程（19页word）.pdf │ 清华大学第四版：普通人如何抓住DeepSeek红利（65页PPT）.pdf │ 厦门大学：大模型概念、技术与应用实践（140页PPT）.pdf │ └─没啥用的，随便看看 │ 1000个DeepSeek神级提示词，让你轻松驾驭AI.docx │ 3个DeepSeek隐藏玩法，99%的人都不知道！.docx │ deepseek 应该怎样提问.docx │ Deepseek 高效使用指南.docx │ Deepseek不好用，是你真的不会用啊！.docx │ DeepSeek小白使用指南，99% 的人都不知道的使用技巧（建议收藏）docx.docx │ DeepSeek最强使用攻略，放弃复杂提示词，直接提问效果反而更好？.</description>
    </item>
    
    <item>
      <title>安装百度飞浆PaddleSpeech</title>
      <link>/ai/%E5%AE%89%E8%A3%85%E7%99%BE%E5%BA%A6%E9%A3%9E%E6%B5%86paddlespeech/</link>
      <pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%AE%89%E8%A3%85%E7%99%BE%E5%BA%A6%E9%A3%9E%E6%B5%86paddlespeech/</guid>
      <description>安装  pip3.9 install paddlepaddle -i https://mirror.baidu.com/pypi/simple pip3.9 install pytest-runner -i https://mirror.baidu.com/pypi/simple pip3.9 install paddlespeech -i https://mirror.baidu.com/pypi/simple 报错1:ImportError: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.22&#39; not found  解决：   find / -name &amp;quot;libstdc++.so.6*&amp;quot; #找到一个路径 export LD_LIBRARY_PATH=/root/anaconda3/pkgs/libstdcxx-ng-8.2.0-hdf63c60_1/lib/:$LD_LIBRARY_PATH 报错2: </description>
    </item>
    
    <item>
      <title>当程序出现了个bug</title>
      <link>/ai/%E5%BD%93%E4%BD%A0%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%87%BA%E7%8E%B0%E4%BA%86%E4%B8%AAbug/</link>
      <pubDate>Thu, 09 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%BD%93%E4%BD%A0%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%87%BA%E7%8E%B0%E4%BA%86%E4%B8%AAbug/</guid>
      <description>今天下午 研发有个数据误更新 需要回滚数据 在利用DBA提供的数据找回功能时 刚好我在旁边看着他在处理 眼瞅着生成的加滚SQL文件没有换行 一个大文本没有分行 所以有文字都在一行上 很难阅读 研发得自已处理下这个文件才能看 我让他换个文本编辑器试一下 结果还是不分行 我问另一个经常用这个功能的同事 以下是对话 - “你以前用的时候也是这样吗？” - 答：oracle就是不会分行,MySQL没问题 - “那怎么没跟我提起过呢“ - 答：以为就只能这样，不分行了处理下也能用 - .... -  我说这是一个bug 得处理一下 所以bug第一步  0.发现问题  一个平台或功能得有个反馈的机制 经常有同事或用户 在使用时发现了问题 不一定会主动反馈 需要有一定的鼓励措施 我在做大多数功能的时候 会强调如果使用过程中有任何问题 都可以找我沟通 每次有人找我反馈问题时 都会积极响应 （有时候是用户操作有问题引起的）  1.确认和复现问题  收到反馈后 需要自己确认和复现这个问题 要有再次触发的条件 某些极端的情况下 可能会很难触发和复现问题 此时需要自己阅读代码 找到可疑的模块 再在脑海里重构流程 从而发现问题 我知道这个能力不是所有人都具备的 但个人觉得这是一个好的程序员 应该具备的能力 在此过程中 有一定的概率会发现 这个问题可能是个bug 可能不是个bug 如果不是bug也需要找到问题所在（通常都是流程的条件不具备）  2.定位bug代码  通过现象 找到问题代码 这个定位过程有长有短 有时候甚至需要很久很久 反复的阅读代码 增加日志 才能定位到问题代码 如果是很长时间以前的代码 那简直是个灾难 也因为这个原因 我不喜欢把项目的架构设计得太复杂 因为时间长了 我可能已经记不得当时是怎么设计的了 就很头疼 在我主导的项目里 都力求简单 类设计通常都是按小模块独立 有时候我也需要阅读和调试别人的代码 讲真的 有的时候真的非常费劲 这可能就是不同人的不同表达差异 我也跟正经的研发同学 聊过这类问题 其中有非常善于review别人代码的 经常发现和定位问题的团队管理人员 他们有一种能力 就是架空与代码层去思考bug 以及某种直觉 猜到可能是哪个逻辑没有处理好 这个真的很厉害 需要长时间的一线代码管理 以及不断的定位和处理bug 才能产生的熟练程度  3.</description>
    </item>
    
    <item>
      <title>【大聪明】微信机器人关机下线</title>
      <link>/ai/%E5%A4%A7%E8%81%AA%E6%98%8E%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%85%B3%E6%9C%BA%E4%B8%8B%E7%BA%BF/</link>
      <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%A4%A7%E8%81%AA%E6%98%8E%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%85%B3%E6%9C%BA%E4%B8%8B%E7%BA%BF/</guid>
      <description>   大聪明下线了  大聪明微信机器人不再提供AI回复 生于2023-02-24，卒于2023-09-08  一些时间点  2023-02-20 计划将ChatGPT搬到微信上 2023-02-24 第一版微信机器人上线，基于ChatGPT3.5 2023-02-25 建群:《大聪明的应答测试》 2023-03-18 支持:百度文心一言 2023-03-20 第一个微信群满员 2023-03-24 支持:GPT4.0和bing Chat 2023-03-29 支持:私聊 2023-04-02 建第二群:《大聪明的2群》 2023-04-02 支持:生成图片 2023-04-04 支持:本地训练的机器人（不需要和外网交互） 2023-04-21 支持:生成语音 2023-04-24 支持:图片识别,可以识别图片内容。 2023-04-25 支持:生成视频 2023-05-12 开始做网页版ChatGPT工作平台(www.top580.com) 2023-09-08 下线,不再提供服务  下线原因  ChatGPT热度已经下降 随着热度下降 更新这个功能的热情也不高 大聪明的最后一次代码更新:2023-05-12 更多的精力我在做网页版的AI应用 主要是AI的私有化训练方面 而ai问答这些基础应用 当前各类ChatGPT应用已经随处可见 体验和实用性比微信大聪明要好很多  一些数据  半年的时间里 大聪明共回复了:9201 条消息 其中:1535条私聊消息,7666 群聊消息 共有557人和大聪明在微信上沟通 互动最多的是:李明浩/dba:747次对话,luluci:305次,顾杰~学生:271次 ChatGPT让彼此陌生的人挤在一个群里 共度这一段探索的旅程 AI还在继续进步和发展 感谢大家半年的陪伴 陪我做了一件有趣的事 青山不改绿水长流 有缘江湖再见  </description>
    </item>
    
    <item>
      <title>训练一个自己的AI机器人</title>
      <link>/ai/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E8%87%AA%E5%B7%B1%E7%9A%84ai%E6%9C%BA%E5%99%A8%E4%BA%BA/</link>
      <pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E8%87%AA%E5%B7%B1%E7%9A%84ai%E6%9C%BA%E5%99%A8%E4%BA%BA/</guid>
      <description> 试用入口
 AI私有化训练的好处  已知ChatGPT之类的大语言模型的数据是在训练时的数据集基础上产生的人工智能 这些AI训练完成后，就不再更新，所以ChatGPT的数据和认知停留在2021年9月份 私有化训练的好处是 可以让AI学习你想要的知识，更新AI的能力 可以训练公司或个人的数据，满足特定的业务需求   训练公司的产品操作手册，用于客服AI    训练一些行业信息，提供信息咨询    用最新的数据，更新AI的知识库    用个人的聊天记录，训练出AI模仿这个人的对话语气    &amp;hellip;    训练需要哪些条件  训练AI一方面需要提供有价值的数据（这个就看积累了） 这些数据最好是文字格式的电子文件:word,excel,pdf,txt&amp;hellip;其中txt格式最佳 以及训练用到的工具  一台或几台高性能带显卡的电脑或服务器（硬件越好，训练得越快） 一个现成的AI(可以是国外的ChatGPT，也可以是自己部署的私有化AI) 如果训练的数据很重要，为了数据隐私可以选用私有化部署AI   如果你没有以上的工具，或不知道如何做私有化训练 请参考以下内容，我们做了一个免费的工具帮你训练一个属于你的私人定制AI  如何训练一个自己的AI机器人 第1步：填写AI名称 填写AI名称 第2步：上传数据  支持pdf,txt等格式 上传的数据越多，训练后的AI对相关的回答越智能 默认上传的数据是真实可信的，ai训练时不会去判断数据是否正确  上传数据 第3步：等待AI训练完成  到这一步后就只需要等着就行 而且需要等很久，建议隔一天再过来看进度。 这里为了演示，我上传的文件很少，也用了 AI训练非常费资源,文件件越多越大，训练用时越长。  等待AI训练完成 训练完成  这里上传了107MB文件，训练用了1个小时。  第4步：等待管理员审批  训练完的AI并不是立即可以用的 管理员（也就是我）会检查一下是否有不合适的内容（只要不出现敏感内容，都会通过的） 审批通过后，会收到一条短信提醒 这个训练好的AI就可以使用了  第5步：开始与新机器人对话  这里我们训练的文件里有大量的2022年国内家电行业的pdf文件 所以AI可以很准确的回答出相关的问题   总结  我们做了一个AI私有化训练平台 平台上的每个用户都可以训练自己的数据，形成属于自己的AI机器人 受制与网络带宽，如果你要训练的数据集很大，请用移动硬盘寄给我 请不要上传训练敏感内容（政治，色情，宗教&amp;hellip;） AI训练用时较长，上传完数据后要耐心等待 训练完成的AI机器人，可以在平台上自由使用  </description>
    </item>
    
    <item>
      <title>怎么通俗的理解向量和数字化</title>
      <link>/ai/%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%90%91%E9%87%8F/</link>
      <pubDate>Thu, 03 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%90%91%E9%87%8F/</guid>
      <description>从《向量数据库》说起  上周同学来望京聊天时 我说最近在做：向量数据库 然后就向他解释 什么是向量 当时我们在楼下公园里遛弯 路边停了一排摩托车 我指着一辆比较酷的摩托给他举例子 意外的很容易他就听懂了 向量的核心是：把世间万物都数字化 一个人，一个美女，一辆车，一条狗 一群僵尸，一段记忆，一句话&amp;hellip; 不管是什么 都用数字来表达  怎么做到向量的数字化呢  比如说：我 怎么用数字来描述我这个人呢 第1个维度： 在这个维度的设定是（物种:人：5001,狗:1001，猪:1002,花:2001,草:2002&amp;hellip;） 我是个人：不是狗，不是猪，不是花，不是草 所以得到一个数字:5001 第2个维度: 在这个维度的设定是（性别，男：1，女:0 ,不男不女:0.5,又男又妇:2,其他:3） 我是纯爷们,得到数字1,现在我的向量是[5001,1] 第3个维度是身高 于是我的向量:[5001,1,174] 第4个维度是籍贯 于是我的向量:[5001,1,174,551] 第5个维度是体重 于是我的向量:[5001,1,174,551,70] 第6个维度是小学学校名对应的数字 于是我的向量:[5001,1,174,551,70,22] 第7个维度是喜欢的运动 第8个维度是喜欢的食物 第9个维度是喜欢的书 第10个维度是脸长 第11个维度是脸宽 第12个维度是眼睛大小 第13个维度是鼻孔大小 第14个维度是腿上有几根毛 第15个维度是肌肉密度 第16个维度是帅气程度 第17个维度是脾气 &amp;hellip;. 于是我的向量:[5001,1,174,551,70,22,....] 维度越多 对我的描述越具体 最终我们定义一下，比如700个维度 那么最终我们用[5001,1,174,551,70,22,....]类似的700个数字定义了我 这一组数字就是我的向量表达  向量 有什么用？  刚才我们用向量表达了我这个人 这样会有什么好处呢 假设： 因为我的帅气英俊加上气宇不凡 有众多的追求者 但是我已经名花有主了 这时候追求者们 对我这个优秀的稀缺资源已经不能再被占有了 于是她们想找个：最接近我的人 这时候怎么办 去向量数据库里匹配向量和我重合度最高的人 这时候就会得到一批非常接近我的人 快去抢吧&amp;hellip; 机会不等人  向量 崩塌  这时候就会有人质疑了 会不会出现一个人的向量和我无限接近 只有某一项或少数几项和我的不一样的人 比如一个各个向量都接近的女版的我？ 比如会不会有条狗跟我的向量表达很近？ 如果向量的维度不够 是会出现的 但是维度足够多 就会避免出现此类向量崩塌的场景 一个女版的我 一定会在其他的很多维度上和我产生明显差异 比如头发，运动能力，比如胸围，比如&amp;hellip; 这就是向量的维度多的好处 大力出奇迹 维度多，细节到位 向量的匹配越真实  向量与AI  到这里是不是已经理解了向量是什么了 再从一句话来说 “帮我写一篇今天晚饭的健康食谱” 这一句话 在向量维度也是用一组数字来表达 首先做分词 再对每个词的词性做数字化 词之间的关联数字化 最终这句话会对应成一个向量表达 [2,82,234,5,22,2197,74.</description>
    </item>
    
    <item>
      <title>Google医疗大模型Med-PaLM突然进化到接近临床医生水平</title>
      <link>/ai/google%E7%9A%84%E5%8C%BB%E7%96%97%E5%A4%A7%E6%A8%A1%E5%9E%8Bmed-palm%E5%B7%B2%E6%8E%A5%E8%BF%91%E4%B8%B4%E5%BA%8A%E5%8C%BB%E7%94%9F%E6%B0%B4%E5%B9%B3/</link>
      <pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/google%E7%9A%84%E5%8C%BB%E7%96%97%E5%A4%A7%E6%A8%A1%E5%9E%8Bmed-palm%E5%B7%B2%E6%8E%A5%E8%BF%91%E4%B8%B4%E5%BA%8A%E5%8C%BB%E7%94%9F%E6%B0%B4%E5%B9%B3/</guid>
      <description>Med-PaLM的进化  7月12日《Nature》发表文章，详解了医疗大模型Med-PaLM的进化过程 研究人员表示，当回答医学问题时，微调后的医疗大模型Med-PaLM表现良好，一组临床医生对其回答的评分为92.6%，与现实中临床医生的水平（92.9%）
  论文原地址：https://www.nature.com/articles/s41586-023-06291-2 有兴趣的同学可以看一下原文   记住这组数字：  在MultiMedQA评估基准下 临床医生对ai的正确率评估是：92.6% 而现实中临床医生正确率水平是：92.9% Google的Med-PaLM大模型还没有正式开放 从他们发表的论文上看 医疗领域的正确率这次提升非常明显 在AI+医疗领域目前Med-PaLM是最先进的AI 比通用大模型:GPT4的正确率要高很多  92.6%是什么水平  临床医生正确率：92.9% Med-PaLM进化版正确率：92.6% GPT4正确率：85.1% 初代版的Med-PaLM正确率：67.2% ChatGPT(GPT3.5)正确率:60.2% 这是个了不起的数据   AI的正确率有哪些影响  ai正确率的影响参考我3个月前的一篇文章: 《职业选择的新思考：ChatGPT是否会取代你的职位？》  AI+医疗领域  在AI+医疗领域，谷歌走在前列。 其最新的医疗大模型Med-PaLM 2为首个在美国医疗执照考试中达到专家水平的大模型。 据华尔街日报报道，自4月份以来，该模型一直在美国梅奥诊所等顶尖私立医院进行测试。 我和几个同学先前讨论过几次 一致认为：教育，律师，会计，医疗 这几个领域是AI最好落地的场景 而这4个领域一定会有专门训练且优化过的专业AI出现 专业的大模型在特定场景下比现在的chatgpt等通用大模型要好用 而伴随着谷歌这次抽风式的进化 AI医疗方面的应用落地 AI检测心电图、X光片会更快的一些医院中投入应用 而AI问诊,AI用药咨询也将快速落地  怎么使用Med-PaLM进化版  目前只有Google的测试结果 没有开放试用 而且这些专业领域的大模型一般会和指定的公司和商家合作 不会对大众开放 我在个人网站上增加了两个医疗ai机器人 基于ChatGPT 正确率一般，跟google此次的进化版有点弱 有想体验的同学也可以试用一下   </description>
    </item>
    
    <item>
      <title>北大法律大模型ChatLaw发布:中国法律界的智能助手</title>
      <link>/ai/%E5%8C%97%E5%A4%A7%E6%B3%95%E5%BE%8B%E5%A4%A7%E6%A8%A1%E5%9E%8Bchatlaw/</link>
      <pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%8C%97%E5%A4%A7%E6%B3%95%E5%BE%8B%E5%A4%A7%E6%A8%A1%E5%9E%8Bchatlaw/</guid>
      <description>7月3日 北京大学信息工程学院袁粒课题组+北大兔展AIGC联合实验室两个团队联合发布了ChatLaw 可能是目前国内比较先进的法律大模型 从实际体验来看 1.在国内法律领域比ChatGPT回答得更专业 2.在其他回答上很勉强，比ChatGPT弱很多,有点呆 3.本地部署非常费资源,对机器要求较高 4.性能不佳，每次回答容易卡住且不流畅 考虑到6月27日幂律智能联合智谱AI法律垂直大模型 PowerLawGLM。 还有再早一点开源社区也发布了一些AI法律微调模型 由于ChatGPT的普及，LLMA的开源 而法律行业的规律性，可文本化，可预测性比较强 大语言模型的崛起为普通人的咨询法律相关问题提供了很多便利  关于ChatLaw 信息汇总  官网地址：https://www.chatlaw.cloud/ 论文地址：https://arxiv.org/pdf/2306.16092.pdf GitHub 地址：https://github.com/PKU-YuanGroup/ChatLaw 根源上这个模也还是基于meta公司的LLaMA模型(小扎的这次开源给国内的大语言模型贡献巨大，现在市面上大多数开源模型都是基于Meta开源的LLAMA） 北京大学信息工程学院袁粒课题组 北大-兔展AIGC联合实验室联合发布 主要团队成员： Jiaxi Cui Zongjian Li Yang Yan Bohua Chen Li Yuan  这是官方宣传视频   这是实际体验&amp;hellip;  问了一个踩到狗屎的问题，等了5分钟，还卡在这   ChatLaw的版本  共有三个版本，分别如下： ChatLaw-13B，为学术 demo 版，基于姜子牙 Ziya-LLaMA-13B-v1 训练而来，中文各项表现很好。但是，逻辑复杂的法律问答效果不佳，需要用更大参数的模型来解决； ChatLaw-33B，也为学术 demo 版，基于 Anima-33B 训练而来，逻辑推理能力大幅提升。但是，由于 Anima 的中文语料过少，问答时常会出现英文数据； ChatLaw-Text2Vec，使用 93w 条判决案例做成的数据集，基于 BERT 训练了一个相似度匹配模型，可以将用户提问信息和对应的法条相匹配。  普通人怎么用上ChatLaw  方法1.官网上申请内测 https://www.</description>
    </item>
    
    <item>
      <title>Langchain的生态链开源产品</title>
      <link>/ai/langchain%E7%9A%84%E7%94%9F%E6%80%81%E9%93%BE%E5%BC%80%E6%BA%90%E4%BA%A7%E5%93%81/</link>
      <pubDate>Wed, 05 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/langchain%E7%9A%84%E7%94%9F%E6%80%81%E9%93%BE%E5%BC%80%E6%BA%90%E4%BA%A7%E5%93%81/</guid>
      <description>Langchain生态 低代码  Langflow: LangFlow是LangChain的UI Flowise - LangchainJS UI：拖放 UI 以使用 LangchainJS 构建自定义的 LLM 流程 Databerry：用于语义搜索和文档检索的无代码平台 LangchainUI: 开源聊天人工智能工具包 Yeager.ai：Yeager.ai Agent 是第一个 Langchain Agent 创建者，旨在帮助您轻松构建、原型设计和部署 AI 支持的代理  服务  GPTCache：用于为 LLM 查询创建语义缓存的库 Gorilla：LLM 的 API 商店 LlamaHub：社区制作的 LLM 数据加载器库 EVAL：带有 Langchain 的弹性多功能代理。 将执行您的所有请求。 Auto-evaluator：使用Langchain进行问答的轻量级评估工具 Langchain Visualizer：LangChain工作流程的可视化和调试工具 LLM策略：使用LLM实现策略模式 datasetGPT：使用 LLM 生成文本和会话数据集的命令行界面。 spellbook-forge：使您的 LLM 提示可执行并受版本控制。 自动评估器: Langchain 自动评估器 Jina：使用 Jina 进行生产的 Langchain 应用程序 Gradio 工具: Gradio LLM 代理 steamship-langchain：Steamship 适配器，使 LangChain 开发者能够在 Steamship 上快速部署应用程序🐍 LangForge：用于创建和部署 LangChain 应用程序的工具包 BentoChain: LangChain 在 BentoML 上的部署 LangCorn: 使用 FastApi 自动为 LangChain 应用程序提供服务 Langchain 服务：带有 Qdrant 矢量存储和 Kong 网关的自定 Langchain 设置 Lanarky: 使用 FastAPI 交付可用于生产的 LLM 项目 Dify：一个用于插件和数据集的 API，一个用于快速工程和可视化操作的界面，所有这些都用于创建强大的 AI 应用程序。 LangchainJS Worker：cloudflare 上的 LangchainJS Worker Chainlit：在几分钟内构建 Python LLM 应用程序 Zep：Zep：LLM/Chatbot 应用程序的长期内存存储 Langchain Decorators：LangChain 顶部的一层，为编写自定义 langchain 提示和链提供语法糖 FastAPI + Chroma：ChatGPT 的示例插件，利用 FastAPI、LangChain 和 Chroma AilingBot：快速将Langchain上构建的应用集成到Slack、企业微信、飞书、钉钉等IM中。  代理  CollosalAI Chat：使用 RLHF 实施 LLM，由 Colossal-AI 项目提供支持 AgentGPT：使用 Langchain 和 OpenAI (Vercel / Nextjs) 的 AI 代理 本地 GPT：受到私有 GPT 的启发，将 GPT4ALL 模型替换为 Vicuna-7B 模型，并使用 InstructorEmbeddings 代替 LlamaEmbeddings ThinkGPT：增强 LLM 并超越其极限的代理技术 Camel-AutoGPT：法学硕士和自动代理（如 BabyAGI 和 AutoGPT）的角色扮演方法 私有GPT：利用GPT的力量与您的文档进行私密交互，100%私密，无数据泄露 RasaGPT：RasaGPT 是第一个构建在 Rasa 和 Langchain 之上的无头 LLM 聊天机器人平台。 SkyAGI：LLM 代理中新兴的人类行为模拟能力 PyCodeAGI：一个小型 AGI 实验，根据用户想要构建的应用程序生成 Python 应用程序 BabyAGI UI：让在网络应用程序中使用babyagi更容易运行和开发，比如ChatGPT SuperAgent：将 LLM Agent 部署到生产环境 Voyager：具有大型语言模型的开放式实体代理 ix：自治 GPT-4 代理平台 DuetGPT：对话式半自主开发助手，无需复制粘贴即可进行 AI 结对编程。 生产环境中的多模式 LangChain 代理: 部署 LangChain Agent 并将其连接到 Telegram DemoGPT：DemoGPT 使您只需使用提示即可创建快速演示。 它在 Langchain 文档树上应用了 ToT 方法。 SuperAGI：SuperAGI - 开发优先的开源自主人工智能代理框架 自主 HR 聊天机器人：一个自主代理，可以使用现有工具自主回答 HR 相关查询 BlockAGI：BlockAGI 进行迭代、特定领域的研究，并输出详细的叙述性报告来展示其发现  模板  AI：Vercel 模板，用于使用 React、Svelte 和 Vue 构建人工智能驱动的应用程序，对 LangChain 提供一流的支持 create-t3-turbo-ai：基于 t3、Langchain 友好的样板，用于构建类型安全、全栈、LLM 驱动的样板 使用 Nextjs 和 Prisma 的 Web 应用程序 LangChain.</description>
    </item>
    
    <item>
      <title>人工智能平台top580.com使用说明_生成视频</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_8/</link>
      <pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_8/</guid>
      <description>准备工作  1.打开www.top580.com 2.登入系统 这一步参见文档:注册和登录的详细说明  2.登入系统  这一步参见文档:注册和登录的详细说明  教学视频   </description>
    </item>
    
    <item>
      <title>人工智能平台top580.com使用说明_生成流程图</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_7/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_7/</guid>
      <description>准备工作  1.打开www.top580.com 2.登入系统 这一步参见文档:注册和登录的详细说明  2.登入系统  这一步参见文档:注册和登录的详细说明  生成流程图 功能介绍  提供一些关键词，让AI依据这些关键词生成指定的流程图 支持流程图,状态图,时序图,甘特图,类图,饼图,关系图  使用说明  平台是业务时间个人写的，刚刚试用，可能会有很多bug和使用不便的地方，欢迎和我反馈
 &amp;hellip;
enjoy it .</description>
    </item>
    
    <item>
      <title>人工智能平台top580.com使用说明_生成图片</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_6/</link>
      <pubDate>Mon, 22 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_6/</guid>
      <description>准备工作  1.打开www.top580.com 2.登入系统 这一步参见文档:注册和登录的详细说明  2.登入系统  这一步参见文档:注册和登录的详细说明  生成图片 功能介绍  提供一些关键词，让AI依据这些关键词生成指定的图片 支持卡通画,简笔画,素描画,中国画,水彩画&amp;hellip;  使用说明  平台是业务时间个人写的，刚刚试用，可能会有很多bug和使用不便的地方，欢迎和我反馈
 &amp;hellip;
enjoy it .</description>
    </item>
    
    <item>
      <title>人工智能平台top580.com使用说明_AI对话</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_5/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_5/</guid>
      <description>准备工作  1.打开www.top580.com 2.登入系统 这一步参见文档:注册和登录的详细说明  AI对话 功能介绍  和ChatGPT进行对话，在对话中解决问题或生成各式各样的文章 支持：闲聊，散文，诗歌，小说，故事，笑话&amp;hellip;.  使用说明  平台是业务时间个人写的，刚刚试用，可能会有很多bug和使用不便的地方，欢迎和我反馈
 &amp;hellip;
enjoy it .</description>
    </item>
    
    <item>
      <title>人工智能平台top580.com使用说明_用户注册和登录</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_4/</link>
      <pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_4/</guid>
      <description>第一步，打开www.top580.com  界面如下图所示   第二步：点击按钮进入 用户登录页  首次加载时，需要大约10秒钟的准备时间 加载成功后，会进入登录页  如果已经注册过的用户，直接用手机号和密码登录 新用户点下方的点击进入试用申请  第三步：新用户注册（可选）  老用户无需此步 认真填写资料后点提交 密码会用【短信的方式】发送到你的手机上 这个密码很重要，记住它 暂时还没做忘记密码功能，如果密码忘了，就没了。切记 -  第四步：登入系统  已经注册过的用户，直接用手机号和密码登录  当你看到这个页面的时候，就表示你登入成功了   第五步：开始使用  进入系统后，就可以正常使用AI功能了 每个AI的使用方式和技巧，会单独出文章 -   平台是业务时间个人写的，刚刚试用，可能会有很多bug和使用不便的地方，欢迎和我反馈
 &amp;hellip;
enjoy it .</description>
    </item>
    
    <item>
      <title>人工智能平台top580.com_使用说明(汇总)</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_3/</link>
      <pubDate>Fri, 19 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_3/</guid>
      <description> 我做了一个智能AI平台 免费使用.让更多的人接触ChatGPT类似的AI智能产品 为防资源滥用,每个用户每天可以和AI对话/生成/次数有限制 未认证用户:【20次/天】 实名验证用户:【50次/天】 用完次数后，需要等第二天再继续。 功能包括： ChatGPT的AI对话 ChatGPT生成图片 ChatGPT生成各种文档，创意文案，诗词&amp;hellip; ChatGPT生成流程图,时序图,类图,甘特图&amp;hellip; ChatGPT生成视频（调试中,暂时未开放） 网址是：www.top580.com 文档1:注册和登录的详细说明 文档2:ChatGPT对话的详细说明 文档3:AI生成图片的使用说明 文档4:AI生成流程图的示例 文档5:AI生成视频的视频讲解 更多功能和使用方式，正在准备中&amp;hellip;  如果你想了解目前该项目的进度:进度更新    </description>
    </item>
    
    <item>
      <title>人工智能平台top580.com_进度更新</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_1/</link>
      <pubDate>Sun, 14 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0_1/</guid>
      <description>试用入口
 当前进度 系统功能  域名转到cloudflare 已完成 阿里云主机注册 已完成 openai的api申请 已完成 azure的api申请 未开始 域名备案 已完成 用户注册 已完成 手机验证码平台 已完成 密码生成下发 已完成   用户登录 已完成 用户权限 已完成  通用AI  文本问答 进行中  结果记录代码 已完成 结果展示优化 已完成 翻译助手 未开始 超长文本 已完成   流程图 已完成 生成图片 已完成 生成音频 40% 生成视频 已完成 图片识别 已完成，代价太大，放弃  定制AI  私有数据上传 已完成 私有数据训练 已完成 私有ai问答 已完成 专用ai 进行中  医疗助手 已完成 症状助手 未开始 药品辅助 未开始 心理辅导 未开始   法律助手 进行中  文律文书生成 已完成 国内法规向量训练 已完成 案件线索 未开始 法规图谱 未开始 模拟法庭 进行中 30%   代码助手 未开始  代码生成 代码解释      其他  多平台ai接入 未开始 隐私离线ai 已完成   按日期更新 20230920  增加图生图功能（用一张图+文字生成一张新的图）  20230918  生成照片列表页改成首页即可见 增加生成3d图标和超现实主义照片的模型 禁用了平台上提擦边球图片的用户，并增加负面提示词防止生成色情图片  20230916  生成照片，脸容易变形的问题修复 这个bug是在去天津的路上修复的，这个bug太恶心了，出来的美女脸一变形跟鬼一样，实在是忍不了  20230915  妹子功能上线，发现脸部总是有点扭曲，待修复  20230914  在二手显卡的帮助下，生成妹子功能取得质的突破，不管是二次元，还是超写实，效果都比以前的好太多。 放弃了以前的生成图片功能和接口，改用全新的训练模型。预计3-5天可以完工。  20230911  生成声音功能规划，最终还是要文字部分区分开来。共用一个LOG表，和视频共用一套流程  20230910  生成视频页面改造，页面动态调整，为生成其他媒体内容改造。  20230908  用户反馈需要忘记密码功能，完成页面增加 70% ,没做完。  20230907  录制《AI私有化训练》教学视频，视频太长，效果不好。  20230906  调整AI生成各种功能时放在不同库表中存储的问题，共用一套库表，共用一个前/后端页面 又买了块二手显卡，用于生成细粒度的人物图（漂亮妹子）  20230905  忙了一段时间没有更新这个AI 继续更新：AI私有化增加：国产,本地模型选项  20230815  正式上线：AI私有化训练功能，离线AI问答功能  20230814  显卡周末到货了，今天花了大半天的时间在安装这个显卡 现有的服务器，台式机的电源都供不上（需要2个8针的750w供电） 叠了台式机和服务器的电源，也没带动 考虑退货了，就先将就着云上资源先用着  20230810  AI训练：完成AI训练完的机器人的问答测试 下单了一块显卡。打算提升一下训练速度  20230806  AI训练：远程调用的问题修复完成  20230802  发布AI训练到线上，发现远程调用有问题  20230730  AI训练：去掉训练完由用户确认的步骤  20230728  增加粗俗的AI,出口成脏，很会骂人 调整现有的ai对话prom类型。将类型人格化  20230725  AI训练：完成流程的初步调试 发现打包上传后出错（原因未定位）  20230724  AI训练：完成用户上传后，后台训练的部分 完成celery的任务互动，完成异步任务 完成内网传透，已节约阿里云费用  20230723  AI训练：AI训练流程增加审核节点  20230720  AI训练：AI训练流程（新建,训练，确认,完成） 制作流程页，主要是用户上传部分  20230718  增加了实时联网的ai：用搜索引擎查询用户输入，返回相应结果（未上线，待私有ai一起打包上线）  20230717  增加医疗ai。去掉文本对话中不常用到的4个ai  20230715  调试完成langchain和向量支持 完成私有ai训练的核心模块（重要）  20230711  生成视频功能出错,bug修复 07-09到07-11 共39个用户生成视频的请求失败。  20230708  私有数据上传页面（前端） 80% 模拟法庭初版页面 30%  20230628  生成视频功能正式开放使用  20230625  生成视频功能补全（上传到阿里云，视频在线播放，视频生成日志）  20230624  生成视频前端页面完成  20230622  生成视频功能完成核心代码（基本能用）  20230617  尝试网站微信扫码登录（用于代替手机短信验证） 失败：我的微信公众号不是用企业名义注册的，无法开通此功能 扫码登录的代码已完成，功能暂不可用  20230614  平台来了很多新用户，系统资源有点紧张 开了阿里云PolarDB，后台数据存储转向RDS 修改了图片生成功能，用户的输入将会被翻译成英语以后，再生成图片。（提高图片的准确性）   20230611  生成视频，去掉审核环节 修复注册页bug ：appuseid传输列表时报错。  20230607  修复ai不能连续对话的bug。ai可以记住历史聊天内容了 修复加载卡住的问题（首页加载时间依旧会过长，还需要做个加载动画） 修复注册页面直接跳到首页的bug ai生成视频功能开始做了  20230530  1.</description>
    </item>
    
    <item>
      <title>要做一个人工智能平台</title>
      <link>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0/</link>
      <pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%B9%B3%E5%8F%B0/</guid>
      <description>功能  在做一个AI智能平台 可以对接多个ai平台 不仅仅是ChatGPT 还支持私有化数据训练 用户可以流畅的在国内访问 用户可以提交自己的私用数据做训练 用户训练的私有数据可以选择是否公开给其他人用 会有模块化的已定义好的ai可以直接用 支持图片,音频,视频,图表的生成 支持针对行业的定制化ai功能  成本  前期完全免费 接受用户反馈 不断迭代改进 等产品成熟了以后 估计在6月份以后 会收取一定的费用 以覆盖服务器的运行成本 理论上应该会非常偏宜 现在估计的运行成本 大约是500元/月 如果有100个用户的话 每个人收5元/月 应该问题不大 实在收不上来 自已负担也没问题  </description>
    </item>
    
    <item>
      <title>微信上的ChatGPT机器人新功能语音的使用说明</title>
      <link>/ai/%E5%BE%AE%E4%BF%A1%E4%B8%8A%E7%9A%84chatgpt%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%A7%8B%E6%94%AF%E6%8C%81%E8%AF%AD%E9%9F%B3%E4%BA%86/</link>
      <pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%BE%AE%E4%BF%A1%E4%B8%8A%E7%9A%84chatgpt%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%A7%8B%E6%94%AF%E6%8C%81%E8%AF%AD%E9%9F%B3%E4%BA%86/</guid>
      <description>上一节内容：
 我在微信上用chatGPT做了个大聪明
 20230421更新  微信ChatGPT机器人（大聪明）开始支持语音回复了 又是一个中看不中用的功能（文字问答才是最简单实用的） 触发语音回复的方式如下图所示  进阶技巧：  大聪明的声音是可以设置的，默认是个青年男子的声音，你可以切换成其他的声音  1.获取声音列表  如下图所示，共有25种声音可供选择，支持中，粤，日，韩，美 等主要语音  1:晓晓,女,中文-内地,活泼、温暖的声音，具有多种场景风格和情感 2:云扬,男,中文-内地,专业、流利的声音，具有多种场景风格。 3:云希,男,中文-内地,活泼、阳光的声音，具有丰富的情感，可用于 4:云健,男,中文-内地,适合影视和体育解说， 5:云夏,男,中文-内地,少年年男声， 6:晓伊,女,中文-内地,女声可定制:angry,sad等9种情绪 7:曉佳,女,粤语-香港,曉佳(HiuGaai),粤语女声 8:曉曼,女,粤语-香港,曉曼(HiuMaan),粤语女声 9:雲龍,男,粤语-香港,雲龍(WanLung),粤语男声 10:曉臻,女,中文-台湾,曉臻(HsiaoChen),湾湾女声 11:曉雨,女,中文-台湾,曉雨(HsiaoYu),湾湾女声 12:雲哲,男,中文-台湾,雲哲(YunJhe),湾湾男声 13:Yan,女,英语_香港,Yan,港式英语女声，不支持中文。 14:Sam,男,英语_香港,Sam,港式英语男声，不支持中文。 15:七海,女,日语_日本,七海(Nanami),日语女声 16:圭太,男,日语_日本,圭太(Keita),日语男声 17:선히,女,韩语_韩国,선히(SunHi),韩语女声 18:인준,男,韩语_韩国,인준(InJoon),韩语男声 19:Ana,女,英语_美式,美式英语，女童 20:Aria,女,英语_美式,美式英语，成年女性 21:Jenny,女,英语_美式,美式英语，成年女性 22:Michelle,女,英语_美式,美式英语，成年女性 23:Christopher,男,英语_美式,美式英语，成年男性 24:Eric,男,英语_美式,美式英语，成年男性 25:Guy,男,英语_美式,美式英语，成年男性 2.切换声音  如下图所示，收到回复后，以后大聪明回复你的语音就会使用新的声音  其他说明  语音回复功能的内容也是从chatGPT中获得的 语音回复比纯文字回复，会额外多用5-20秒用时 语音回复在群聊和私聊模式都可以用 另外，经过最近几个星期的测试，私聊功能对一些对隐私比较重视的朋友更友好。 继续开放一些私聊的名额，加大聪明为好友通过以后即可一对一聊天。  加群（推荐）： 加大聪明的微信，进行一对一私聊（不推荐）：  请不要在私聊和群里谈论或诱导机器人谈论敏感话题。
 </description>
    </item>
    
    <item>
      <title>职业选择的新思考：ChatGPT是否会取代你的职位？</title>
      <link>/ai/chatgpt%E7%9A%84%E5%8F%91%E5%B1%95%E4%BC%9A%E6%9B%BF%E4%BB%A3%E5%93%AA%E4%BA%9B%E8%81%8C%E4%B8%9A/</link>
      <pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/chatgpt%E7%9A%84%E5%8F%91%E5%B1%95%E4%BC%9A%E6%9B%BF%E4%BB%A3%E5%93%AA%E4%BA%9B%E8%81%8C%E4%B8%9A/</guid>
      <description>从AI回答的正确率说起   在微信上建了一个叫大聪明的chatGPT的机器人
  具体看这里: 《我在微信上用chatGPT做了个大聪明》
  中午科长说他经常会跟大聪明聊天沟通想法
  我劝他不要肓信ai的回复
  因为ai的首要目的不是“保真” ，而是“保回复质量”
    像chatGPT之类的大语言模型当然想追求答案的正确性
  但正确性对AI来说还是有点难
  他更像是个博学的学生
  什么都知道一点
  什么都能聊得起来
  但是做不到严格的“正确性”
  虽然给人的感觉是非常聪明
  但那是因为它会得多
  语言组织能力强产生形成的印象
  举例来说
  现在用得最普遍的ChatGPT3.5 和GPT-3.5 的正确率大约是58%
  ChatGPT4的正确率在64%左右，GPT-4的正确率在77%左右
   而人类借助于专业分工，常年的社会网络交流以及借助于资料阅读和工具可以做到（80%-99%)的正确率  现阶段的AI（80%正确率）  现在最顶级的AI(GPT-4)的正确率80% ，接近人类的普通专业人士 这个阶段AI只能是辅助工具 AI现阶段不能代替人类做决定 AI的每一个决定需要人工确认以保证结果是正确的 也就是说AI只是个辅助工具 用来做提升人类的工作效率 但是它的准确性不足以超过人类的信任区域 1.</description>
    </item>
    
    <item>
      <title>ChatGPT的胡说八道</title>
      <link>/ai/chatgpt%E7%9A%84%E6%8F%90%E9%97%AE%E6%8A%80%E5%B7%A7/</link>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/chatgpt%E7%9A%84%E6%8F%90%E9%97%AE%E6%8A%80%E5%B7%A7/</guid>
      <description>前段时间我建了一个微信群，里面接入了chatgpt和百度文心一言的机器人 建群的目的有两个  让没有用过chatgpt的朋友体验一下chatGPT的魔力 我看一下大家（尤其是非技术人员）怎么跟chatgpt对话的   目前这个群里大约有200多人，有各行各业的人，技术/行政/法务/管理/学生/自由职业/艺术&amp;hellip; 多数是随着我的文章加进来的 里面很热闹，有很多奇怪的人问了chatgpt奇怪的问题  问题分类   大家在群里跟chatGPT聊天大约分成以下几类：
 打招呼好奇类：一般是在试探chatGPT能干啥 探索类：比上一类要稍懂一些，而且已经有过一定的使用经验。他们可能是在网上或者自己想出来一些奇怪的问题来试探chatGPT 问时事，问新闻：把chatGPT当成一个对话机器人，问当前时事，问股票，问彩票，问各种新闻 解决问题：问当出现什么报错时（一般是技术问题） 应该怎么做？ 写文档：总结，创意，套话&amp;hellip; 调戏chatgpt：不知道从哪学来的奇怪的话术，在那调戏chatgpt    以上这些，只有5是chatGPT擅长的。
   （未完待续)</description>
    </item>
    
    <item>
      <title>ChatGPT向左,百度文心一言向右.md</title>
      <link>/ai/chatgpt%E5%90%91%E5%B7%A6%E7%99%BE%E5%BA%A6%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80%E5%90%91%E5%8F%B3/</link>
      <pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/chatgpt%E5%90%91%E5%B7%A6%E7%99%BE%E5%BA%A6%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80%E5%90%91%E5%8F%B3/</guid>
      <description> “ChatGPT向左,文心一言向右”:同一条赛道上的两个方向，一个深耕技术，一个用心做产品，但是他们都会成功。
 新闻连着看  3月14日，OpenAI发布GPT-4  比震惊世界的chatGPT(3.5)再次升级：创造力提升，视觉输入，更长的上下文，更强的推理能力。   3月16日，百度发布文心一言  现场演示的时候选择直接放录好的视频，而且采用邀请码的方式没有开放试用，被质疑能力不足（事实上也确实如此） 在开放的试用过程中，被用户发现文字理解有点呆（这个是预期内的，肯定会离chatgpt会有不小的距离）以及更为严重的生成图片时疑似用了国外的图片生成程序（现实是肯定用了国外的图源做训练和标记了，是否用的国外开源产品改的，还不确定）   3月24日，OpenAI发布ChatGPT Plugins  官方演示了Web浏览器，代码解释器，检索信息等方面的Demo   3月27日，百度闭门会议悄悄发布AI服务平台“文心千帆”  现场演示了：对话机器人,三分钟做ppt,数字人直播带货,订机票和酒店等操作。    现状 目前都认可的事实：  ChatGPT的技术还是遥遥领先与世界上的其他竞争对手 百度的大语言模型文言一心已经做出来了，效果虽然赶不上ChatGPT，但至少在中文领域还是可以的（我是3月21日才开始试用文心一言的，并在当天将其接入了我的微信机器人群里）  各自的方向：  技术层面 GPT在一步一步的疯狂往前探索，据说GPT-5已经在内部做安全测试了。AIGC技术这块目前是没有对手的 百度还在努力追赶，可能不远的将来能达到chatGPT初代的中文水平（GPT-3.5），一般预测在3-12个月内可以实现 产品层面 OpenAI公司开始做Plugins，也就是说提供给第三方施展的空间，做一个生态圈，走的是用技术挣钱的方向 百度从文心千帆的闭门会议可以看到一个趋势，就是他自己把AIGC周边的产品都做了，准备往卖服务，用产品挣钱的方向走 形象点说 GPT是技术大牛，开放它的能力，众多第三方开发者一起跟着它做产品。大家一起跟着吃肉喝汤。 文心一言的文心千帆则是直接面向了商家客户，来我这里有现成的产品，你用不，收点钱。 做为开发者，肯定支持GPT这种开放策略，事实上早在几个月前，各种周边的GPT衍生功能产品已经满天飞了，各路开发人员都在给它做各种补充功能：生成PPT,生成视频,翻译软件,pdf检索等等，而官方不断的开放和迭代GPT的能力，语音识别能力，图片输入能力等等。形成了比较好的良性互动 但是从百度的角度，技术上肯定追不上ChatGPT了，但是它可以在产品上下功夫，将开源社区众多开发者的主意，用自己的原生力量打磨出来，做出一个又一个实用且好用的商业化产品，也确实是个更好的选择。挣钱嘛，不寒碜。而且  1.国内短时间还没有哪家ai大语言模型技术能追上百度 。 2.挣完钱以后可以反哺技术，加快追赶的脚步。 3.这是一种很取巧但是实用的路子，百度文心千帆演示的产品中技术难度都不大，采用或者说揉合了开源的或国外现成的很多技术 4.这些产品网上的很多个人开发者都可以短时间完成开发比如:ai生成ppt,ai生成数字人,ai生成行程，但百度拥有的资源做出来的产品肯定会更加好用和精艳。    图：文心千帆企业试用用户：
接下来，我们从百度的闭门会议中发布的ai产品中看看它的技术背景
百度的AIGC产品：文心千帆 场景一：企业办公场景：3分钟制作PPT  和金山wps结合，几句话就可以生成一个精美的ppt,亮点是可以从公司网站上提取信息下来 这个技术难度不大，我在今年2月10号左右，也用chatgpt做了个类似的功能，但是实话说生成的ppt非常丑，远不如这个好看 所以该演示难度对百度来说几乎没有，但是功能非常有用 演示的视频如下：  场景二：电商服务场景：快速生成ai视频  一键生成文案，再用ai数字人技术生成直播视频 技术难度：中等，如果百度是完全自研的那么这个技术难度就有了（事实上应该不是） 开源的方案有，可以用微软的edgeTTS生成语音和字幕，用midjourney生成形象,用DID生成视频 有理由怀疑百度直接用了这些现成的方案（这也是各种数字人用的一整套技术），当然内心里我更希望更有出息一点，自己搞一套 演示的视频如下：  场景三：旅游服务场景：生成旅游规划并完成订单 场景四：金融投资场景：归纳业务评估生成投资建议 总结  百度的文心一言，技术上可以做到国内最优，且始终和国外的先进技术存在很大的落差。 百度的文心一言产品会在商业上产生很大的成功。尤其是toB业务 大语言模型AI,会极大的提高很多职业的工作效率，快跟上，别掉队。  </description>
    </item>
    
    <item>
      <title>百度文心一言发布会,未来可期:为什么我对百度充满信心</title>
      <link>/ai/%E7%99%BE%E5%BA%A6%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80%E5%8F%91%E5%B8%83%E4%BC%9A%E8%A7%82%E5%90%8E%E6%84%9F%E7%9C%8B%E5%A5%BD%E7%99%BE%E5%BA%A6/</link>
      <pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E7%99%BE%E5%BA%A6%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80%E5%8F%91%E5%B8%83%E4%BC%9A%E8%A7%82%E5%90%8E%E6%84%9F%E7%9C%8B%E5%A5%BD%E7%99%BE%E5%BA%A6/</guid>
      <description>百度文心一言发布会  3月16日14:00 百度文心一言发布会准时开始 当李厂长拿出ppt来演示，所有ai对话用录好的视频来播放时。 百度股票嗖嗖的下来了 因为一个ai产品不敢现场演示，也不敢开放试用。很难让人信服。  不看好的观点  在微博和微信群里看大家的反馈 大多数人都觉得不太看好百度的文心一言。 其核心点就在 1.于李彦宏现场露怯，主动说了不如chatGPT，其实也没人会认为百度能赶上ChatGPT 2.现场没有演示，demo部分直接放视频，这是非常明显的怕翻车 3.采用邀请码的方式，大概率只会在固定的群体里试用，没有对公众开放，也是信心不足的表现  我的观点  发布会没开之前，我在上班的路上想了几条，发布会的事   - 3月16日的发布会不会跳票，架子都搭好了，再不上去，股价还要不要了 - 李厂长将会亲自上台，演示百度all in ai不是说着玩的 - 不会开放给大家试用，需要排队等待试用机会 - 会拆分出来很多个不同的Ai，有写诗的，有谱曲的，有写小作文的，有写代码的，有总结分析的，有翻译的，有生活助手的，也有瞎聊的…怎么也得分成20个吧 - 现场演示将会很炸（预设好的demo，不给力是不可能的） - 比chatgpt更懂中文，无敌的中文语料库 - 比chatgpt更实时，数据是当天的 - 会演示：在线教育，写代码，写诗，法律援助，实时推荐， - 会开放api和训练合作，已经有商务合作的有…..巴拉巴拉，顺手展示合作伙伴的成功案例 - 会有图片和视频方面的处理能力 - 文心一言，文言一心…经常说错的同学不要担心，换个简单好记的名字 - 持续改进中，我们也是：未来可期..  正确率90%吧 核心点是我觉得百度这次是不会开放给大家用的 因为产品肯定没成熟 但这不妨碍百度在【生成式AI】这个赛道上领先 百度也是国内最有机会站在生成式AI舞台的公司。  看好百度的原因  大厂里第一个正式发布对标ChatGPT的产品。还隆重的开了个新闻发布会 发布会的演示里的那些流畅的对话可能是精心准备的，但可以理解百度的技术已经接近演示里的水平了 百度确实有着国内最强的AI技术储备，这么多年的ALL IN AI 也没白做 如李彦宏多次强调的那样，这么多年的搜索积累，在中文语言的处理上，处于独一无二的位置 百度有着无可比拟的中文语料优势：最大的中文搜索引擎/百度百科/知道 因为有先发优势，会有很多友商和百度合作，已经有很多很多厂商宣布在和文心一言内测合作 还有最重要的原因，发布会也提了：国内这块技术的不足导致的饥渴。 国内这块的技术需求在那，急需一个产品，哪怕是个半成品 ChatGPT国内用不了，就算用不了，也还是会担心中美关系恶化后的被卡脖子。以及数据泄露的问题   所以百度的文心一言，不管产品是否能成功，百度都能是最后的赢家。因为它站在不可替代的位置，国内没人挑战文心一言，它就能立于不败之地。  最后  群里有个聪明人，给GPT4提了一个非常搞笑的prompt：  @gpt4 百度也推出了一个LLM叫做文心一言。请你用一种阴阳怪气的语气对此做出评价，总体的思路是挖苦讽刺。要有具体的例子（比如过往失败的产品，提及那些产品的糟糕体验。注意不要直接说那些糟糕体验，而是通过反讽、幽默的类比等方式来说明）。  然后ChatGPT反馈：  你好，这是GPT-4。我听说了百度推出了一个LLM叫做文心一言 。我觉得这是一个很有创意的名字，就像百度的其他产品一样，比如百度云、百度贴吧、百度糯米等等。😊 文心一言是百度对标OpenAI的ChatGPT ，也就是GPT-3.</description>
    </item>
    
    <item>
      <title>GPT-4的新功能以及我基于GPT-4做的微信机器人</title>
      <link>/ai/gpt-4%E7%9A%84%E6%96%B0%E5%8A%9F%E8%83%BD%E4%BB%A5%E5%8F%8A%E6%88%91%E5%9F%BA%E4%BA%8Egpt-4%E5%81%9A%E7%9A%84%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/gpt-4%E7%9A%84%E6%96%B0%E5%8A%9F%E8%83%BD%E4%BB%A5%E5%8F%8A%E6%88%91%E5%9F%BA%E4%BA%8Egpt-4%E5%81%9A%E7%9A%84%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/</guid>
      <description>GPT-4的发布  在震惊科技行业的AI聊天机器人ChatGPT发布近四个月后 OpenAI公司又发布了为ChatGPT提供支持的更为强大的下一代技术版本GPT-4 今天(3月15日)凌晨1点，ChatGPT创始人Sam Altman发布了一篇推特：   正式的发布了GPT-4 Sam用五个形容词评价它：capable（adj.能力强的）、aligned（adj.符合预期的）、flawed（adj.有缺陷的）、limited（adj.能力有限的）、impressive（adj.令人印象深刻的）  GPT-4 的升级  相对于GPT3.5，训练参数量上的差别如下：  它可以生成、编辑和与用户迭代创意和技术写作任务，例如创作歌曲、编写剧本或学习用户的写作风格。 它支持生成和处理多达32,768个token（约25,000个单词）的文本，这使得它能够比以前的模型创建或分析更长的内容。 它在各种专业和学术基准测试中表现出“人类水平”的性能，例如通过模拟律师资格考试、法学院入学考试（LSAT）、研究生入学考试（GRE）量化部分和各种AP科目测试。  据 OpenAI 透露，GPT-4 通过了所有基础考试而且是高分通过。例如，GPT-4 在模拟律师资格考试的成绩在考生中排名前 10% 左右，在 SAT 阅读考试中排名前 7% 左右，在 SAT 数学考试中排名前 11% 左右。相比之下，曾经令人震撼的 GPT-3.5 ，真实得分在倒数 10% 左右，GPT-4 的强大已经可想而知。 下面这张图是GPT-4在各项考试中的表现，碾压GPT-3    它可以处理图像输入，并对场景进行识别和描述。  可以看懂图片，并找到这张图片为什么搞笑：巨大的过时VGA接口给小巧的现代智能手机充电    它可以处理表格、图形和图表等数据，并进行分析和解释。     支持更多的数据类型输入      如何用上GPT-4.  现在ChatGPT plus会员有试用，但暂时还没有开放识图功能，且有条数限制 开发者在此页面申请：https://openai.com/waitlist/gpt-4-api 加入等待列表。收到邮件后就能用     微软bing的chat已经升级到4.</description>
    </item>
    
    <item>
      <title>带着chatGPT的NewBing</title>
      <link>/ai/%E5%B8%A6%E7%9D%80chatgpt%E7%9A%84newbing/</link>
      <pubDate>Mon, 27 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E5%B8%A6%E7%9D%80chatgpt%E7%9A%84newbing/</guid>
      <description>NewBing的申请通过了。
应该是现在国内使用chatgpt最方便的方式了</description>
    </item>
    
    <item>
      <title>我在微信上用chatGPT做了个大聪明</title>
      <link>/ai/%E6%88%91%E5%9C%A8%E5%BE%AE%E4%BF%A1%E4%B8%8A%E7%94%A8chatgpt%E5%81%9A%E4%BA%86%E4%B8%AA%E5%A4%A7%E8%81%AA%E6%98%8E/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E6%88%91%E5%9C%A8%E5%BE%AE%E4%BF%A1%E4%B8%8A%E7%94%A8chatgpt%E5%81%9A%E4%BA%86%E4%B8%AA%E5%A4%A7%E8%81%AA%E6%98%8E/</guid>
      <description>update  2023-04-21 支持语音回复和跟读，有25种声音可选 语音的使用说明 2023-04-04 ChatGPT自带的生成图片功能太吓人了，图片上的人脸跟鬼似的（可能是为了版权考虑，把人脸做了特殊处理），看得受不了，图片部分换成了百度的文心一言  大群不再踢人，不再接收新人加入（认识的朋友还是可以加的），另起一个群接受新人加入，新起的群没有实名制要求. 两个群的权重是3:1 的关系，大群里的内容更容易得到更及时的反馈。   2023-04-02 做了以下修改  修改了机器人的回复框架，从底层重写了一版，回复速度更快（原始版本写得太2了） 群里的聊天可以分辨出是具体的人。（这个很重要&amp;hellip;) 修改了提示词，每次都要@大聪明太费劲了。现在以“请”开头的群聊，都会触发大聪明的回复 增加了生成图片的能力，例生成图片:驴肉火烧 生成语音，视频，ppt&amp;hellip;的功能也准备就绪了，炫酷有余，但实用性不佳。先试试图片的反馈。好玩就会继续跟进放开。 减少了一些功能  暂时停用了gpt4,bing,文心一言的功能，用得人少，稳定性不如GPT3.5 停用了私聊功能，不再让大聪明一对一的回复问题（不这样做的原因是，有人在私聊里发消息略微有点频繁，机器人忙着回复私聊信息，群里的消息回得卡顿了）  私聊功能是个很纠结的点，我相信一定有人更愿意在私聊窗口和机器人对话，而不喜欢在群里对话，但是对我来说这个功能就很累赘。会针对几个朋友保留这个功能     前几天在力哥的帮助和推荐下，群里开始要求实名制，甚至把我拉进去的朋友也给踢了。有朋友表示理解，也有朋友私聊我表示很生气。  支持力哥的想法。力哥是个很有想法的人，我也想学习一下他看待新事情的思维和办事方法。  核心点是&amp;quot;如果你的群里的人连改个名字都不愿意配合你，那这个群对他是没有价值的，你留他在群里干啥&amp;quot;   也希望这个群能更好玩，不要有戾气，否则就违背初衷没意思了，拉这个群就是给朋友们感受一下chatgpt的好玩的用法。 要不要多组几个群，喜欢认真的人在一个群里，喜欢瞎扯的人在另一个群里。互相不打扰。  谈正事的群里，会要求实名。 瞎聊天的群里，就各种随意。 区分是正事的群里的消息回复速度更优先一些，假如两个群里同时都有人在和大聪明交谈，那么机器人会更倾向于谈正事群（渣男算法&amp;hellip;）     关于群成本的问题 群里回复消息调用了chatgpt的api，这个确实是收费的，但是费用极低，可以忽略不计 以现在的提问频率，每天大约花费1/3个茶叶蛋的钱，这个还是负担得起的，不要慌&amp;hellip; 真正的成本在于投入时间维护和改造，好在我是个爱玩的人，这件事还挺好玩的，所以：问题不大。   2023-03-29 任何人都可以和大聪明发起一对一私聊了。不需要额外申请。 gpt4的接口报错太多，暂时禁用了，有时间再修复。 实在懒得去维护加群申请，力哥建议由他来管理群成员。 群管理员交给力哥了。 2023-03-23 修复百度文心一言回复不完整的bug ,增加文心一言生成图片功能  对于想和大聪明私聊的同学，可以一对一和大聪明发起对话了。 私聊中不需要再以 @大聪明 开头了，因为是一对一对话。 开通后会一直有效，不需要再次激活，以后任意时间给大聪明发的消息，默认都是机器人回复。 2023-03-23 21:08 此功能试用中，等稳定了，再继续开通。   2023-03-20 群满员了，现在需要加微信由管理员拉进群。 群主每天会在19:00-20:00 集中处理加群邀请  怎么加入群？  扫描这个二维码，加入群 免费使用，没有限制，只有一条，不要讨论或引导机器人讨论敏感话题免得群被封号。  加大聪明的微信，进行一对一私聊（不推荐）： 怎么提问？  把问题写出来，然后 @大聪明。等个几十秒大聪明调用GPT3.</description>
    </item>
    
    <item>
      <title>有趣的数据_ChatGPT的多语种训练数据集</title>
      <link>/ai/%E6%9C%89%E8%B6%A3%E7%9A%84%E6%95%B0%E6%8D%AE_%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E8%AE%AE%E7%94%A8%E8%8B%B1%E8%AF%AD%E5%92%8Cchatgpt%E6%B2%9F%E9%80%9A/</link>
      <pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E6%9C%89%E8%B6%A3%E7%9A%84%E6%95%B0%E6%8D%AE_%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BB%BA%E8%AE%AE%E7%94%A8%E8%8B%B1%E8%AF%AD%E5%92%8Cchatgpt%E6%B2%9F%E9%80%9A/</guid>
      <description>为什么建议用英语和ChatGPT沟通 为什么chatGPT中文对话时候偶尔会感觉到他在胡编瞎造 为什么chatGPT中文提问专业问题时偶尔会出现英语回复  看openai公布的GPT-3训练数据集的语言占比,中文语料只占总训练量的0.1%
   lang 语言名 训练集 占比     en 英语 181014683608 92.65%   fr 法语 3553061536 1.82%   de 德语 2870869396 1.47%   es 西班牙语 1510070974 0.77%   it 意大利语 1187784217 0.61%   pt 葡萄牙语 1025413869 0.52%   nl 荷兰语 669055061 0.34%   ru 俄语 368157074 0.19%   ro 罗马尼亚语 308182352 0.16%   pl 波兰语 303812362 0.</description>
    </item>
    
    <item>
      <title>探索chatgpt</title>
      <link>/ai/%E6%8E%A2%E7%B4%A2chatgpt/</link>
      <pubDate>Fri, 17 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E6%8E%A2%E7%B4%A2chatgpt/</guid>
      <description>  探索一下chatgpt的背景和应用场景
  以下是ppt截图
                                                                                              </description>
    </item>
    
    <item>
      <title>翻译Sam Altman的博客《How To Be Successful》</title>
      <link>/ai/%E7%BF%BB%E8%AF%91samaltman%E7%9A%84%E5%8D%9A%E5%AE%A2howtobesuccessful/</link>
      <pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/%E7%BF%BB%E8%AF%91samaltman%E7%9A%84%E5%8D%9A%E5%AE%A2howtobesuccessful/</guid>
      <description>写在前面  这是上周看到的Sam Altman一篇博客. 原文连接是: https://blog.samaltman.com/how-to-be-successful 周末在家尝试翻译一下 别问为啥不用chatGPT翻译 周日下午15:35 开始翻译的,中间因为吃饭.看剧打断了几次 最终翻译完已经是晚上23:50了 最终用时在3个小时左右 所以机器翻译10秒的事. 我自己上手就需要2-3个小时哼哼哧哧的才能勉强完成.  作者简介  Sam Altman,1985年4月22日,出生于美国伊利诺伊州的芝加哥。 8岁时学会了编程。9岁时收到一台电脑作为生日礼物， 2005年，他选择从大学辍学，同好友合作创办了社交媒体公司 2012年，他以4300万美元的价格将其出售。 2011年，任Y Combinator的合伙人，成为世界上最富有的企业家和天使投资人之一。 2015年，与时任特斯拉和SpaceX首席执行官的埃隆·马斯克共同创立了OpenAI。他们成立这家非营利性人工智能公司的目标是——确保人工智能不会消灭人类。 现为Y Combinator 总裁、人工智能实验室OpenAI首席执行官。 美国《商业周刊》最优秀年轻企业家 被媒体称为ChatGPT之父。 他的博客地址是:https://blog.samaltman.com/  &amp;ndash; 以下是正文
《How To Be Successful》怎么才能成功  I’ve observed thousands of founders and thought a lot about what it takes to make a huge amount of money or to create something important. Usually, people start off wanting the former and end up wanting the latter.</description>
    </item>
    
    <item>
      <title>从一张图了解ChatGPT会改变哪些行业(职业)</title>
      <link>/ai/chatgpt%E5%8F%AF%E4%BB%A5%E6%94%B9%E5%8F%98%E5%93%AA%E4%BA%9B%E8%A1%8C%E4%B8%9A/</link>
      <pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/chatgpt%E5%8F%AF%E4%BB%A5%E6%94%B9%E5%8F%98%E5%93%AA%E4%BA%9B%E8%A1%8C%E4%B8%9A/</guid>
      <description>从ChatGPT对外投资图说起  当我们讨论ChatGPT将改变哪些行业的时候,可以换个思路想 当前对ChatGPT能力理解最清楚的人是谁 肯定是ChatGPT的管理人员,董事会成员,和投资股东  拿了投资方微软的巨量资金后,ChatGPT将这部分钱用于研发和提升产品之余 也成立了openAI基金,投资了一系列的创业公司   看看ChatGPT投资了哪些公司 !
 从图上可以看到ChatGPT投资的公司,大致为成两类 上游: 可以让自己的ai进化 下游: 可以让自己的ai可以改进和提升的领域. 所以ChatGPT的管理团队认为可以有所作为的行业:  1.教育 2.记录/文书 3.法律    学生 (帮助)  由ChatGPT代写作业，已经成为美国大学的一种现象 调查发现，89%的美国大学生已经在用ChatGPT写作业。这就意味着，ChatGPT已经可以从事初级的乃至更高水平的学术研究。 对大学以下的中小学习题,chatGPT可以解答大量的基础题目,给出正确的答案和解题思路 可以用来做作业,也可以用来当成解题助手,家庭老师 同时因为ChatGPT的代写作业能力太强.相应的老师的反作弊工作也提上日程 所以我们看openAI基金投资了:Milo	家长虚拟助理  教师 (部分替代,挑战)  一方面老师们都开始担心学生使用ChatGPT这一技术作弊 另一方面,也要考虑考虑自己的工作安全,部分教师的工作(帮学生解答习题) 随着不断的进化,ChatGPT“迟早可以作为一名老师轻松地授课了”。 所以我们看openAI基金投资了:Speak	AI英语学习平台  记录/文书  录入员,会议记录类工作会被ai工具更有效率的替代 就像这张微软放出来的demo图中,会议中每个人的发言断点,会议提出来的工作项,提醒项,ai都能很好的完成 所以我们看openAI基金投资了:Mem Labs	记笔记应用   法律类工作：  律师助理和法律助理等法律行业工作人员也是在进行大量的信息消化后，综合他们所学到的知识，然后通过撰写法律摘要或意见使内容易于理解。 这和ai的训练路径是一样的,信息消化和学习,是ai最擅长的部分. 所以我们看openAI基金投资了:Harvey	Al法律顾问 参考这篇文章: https://www.lawnext.com/2022/11/stealth-legal-ai-startup-harvey-raises-5m-in-round-led-by-openai.html   会计类工作：  ChatGPT将会很轻松地把财务人员从银行对账、月末入款提醒、进销项差额提醒、增值税验证等这些枯燥重复、初级的工作中解放出来。 甚至，对于是一些专业的财务报告撰写也会带来翻天覆地的影响。 好处是这不仅极大缓解了会计人员的工作强度，而且其凭借客观、准确和及时的特点也很大程度上加强了会计信息的相关性和可靠性。 所以我们看openAI基金投资了:Kick	会计软件  其他类型工作 技术类工作：程序员们  ChatGPT可以快速生成部分基础代码,意味着一项工作在未来可以用更少的员工完成  媒体类工作：广告、内容创作、技术写作、新闻  ChatGPT可以快速生成部分基础代码,意味着一项工作在未来可以用更少的员工完成  客服人员类工作  智能客服的能力,会在ai能力提升,更多的代替人工客服.</description>
    </item>
    
    <item>
      <title>5分钟让你了解ChatGPT是什么</title>
      <link>/ai/chatgpt%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8/</link>
      <pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/ai/chatgpt%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8/</guid>
      <description>开门见山  这是一个AI聊天机器人,2022年11月30日发布 如果你从来没有试过ChatGPT的对话 请记得要尝试去体验一下: https://chat.openai.com/chat  如果你不会科学上网 可以用这个地址体验: http://www.580top.com/dboop2023 (访问人数太多,临时加了ip限制,每个ip每天最多可提交10次左右的问题.) ​这是我业余时间为不懂技术的朋友做的一个页面 无需vpn,无需账号,直接就可以提问   火遍全网的chatGPT是什么? 专业的介绍  ChatGPT是OpenAI开发的一个大型预训练语言模型。它是GPT-3模型的变体，GPT-3经过训练，可以在对话中生成类似人类的文本响应。ChatGPT 旨在用作聊天机器人，我们可以对其进行微调，以完成各种任务，如回答问题、提供信息或参与对话。与许多使用预定义的响应或规则生成文本的聊天机器人不同，ChatGPT经过了训练，可以根据接收到的输入生成响应，从而生成更自然、更多样化的响应。  通俗的介绍: 你可以理解为它是一个聊天机器人,这个机器人会的东西比在此之前的聊天机器人更丰富一些,表现在:
 它有更强的语言理解能力 (更能听得懂人话) 它有更强的语言组织能力 (说的话更符合人类的预期) 它有强大的创作能力AIGC（利用人工智能技术自动生产内容）  以上三点都比在此之前的AI表现得更好,更丝滑,使整个ChatGPT的效果体验非常的惊人.所以突然爆火
ChatGPT是谁做的? 股权在哪家机构? 简单的说:始于Altman和Musk的10亿美元,目前受益最大的是微软.
 2015年，山姆·阿尔特曼与埃隆·马斯克、彼得泰尔、雷德霍夫曼等大佬在[罗斯伍德桑德希尔酒店]吃了一顿晚饭,决定创建一个新的人工智能实验室。 山姆·阿尔特曼（Sam Altman）: 时任知名初创公司孵化器Y Combinator负责人，现为OpenAI联合创始人兼首席执行官 埃隆·马斯克(Elon Musk): 硅谷钢铁侠,特斯拉,SpaceX &amp;hellip;  他们创立了OpenAI,马斯克和阿尔特曼立志用10亿美元的初始资金，打造对人类友好的人工智能，以非营利组织为主体，定期向公众开放AI研究成果和专利。 OpenAI研发的GPT-1、GPT-2模型均对外开源，向外部开发者共享代码和数据。 2018年，马斯克以理念不和为由宣布退出OpenAI，顺带把一些相关研发人员挖去了特斯拉。OpenAI一度被外界调侃成“特斯拉的AI技术人才输送站”。 OpenAI宣布重组，由非营利性的母公司OpenAI Inc和营利性的子公司OpenAI LP组成。至此，OpenAI也从非营利实验室转型为“利润上限”公司，这为投资者和大型科技公司的投资打开了通道，他们的回报上限为投资的 100 倍。 资本开始登场,2019年7月，微软宣布以10亿美元入资OpenAI。一个重要的前提是，微软有权将OpenAI的部分技术商业化，同时，双方达成一项多年的合作协议 2020年，GPT-3完成迭代出现了商业化用例，同年9月，微软宣布获得GPT-3模型的独家授权,其后微软多次追加投资。 2022年11月30日ChatGPT聊天机器人上线。发布仅一周的时间，就已经拥有超100万用户。发布2个月后活跃用户过亿  OpenAI的股权投资协议模式  OpenAI选择了—种新的股权投资协议模式。未来盈利后的OpenAI的利润分配将按照以下四个阶段进行。 第—阶段将优先保证埃隆马斯克、 彼得泰尔、 雷德霍夫曼等首批 投资者收回初始资本； 在第二阶段，微软将有权获得OpenAl75%的利润，直至收回其130亿美元投资； 第三阶段，在OpenAI的利润达到920亿美元后，微软在该公司 的持股比例将下降到49%, 剩余49%的利润由其他风险投资者和OpenAI的员工分享。 第四阶段，在利润达到1,500亿美元后，微软和其他风险投资者的股份将无偿转让给OpenAI的非营利基金。  国内的chatGPT能力:百度占优  chatGPT的火爆上线后,国内同类型产品的研发就已经在开展.</description>
    </item>
    
  </channel>
</rss>
